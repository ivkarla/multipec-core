{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ee495",
   "metadata": {
    "executionInfo": {
     "elapsed": 1682,
     "status": "ok",
     "timestamp": 1754760378335,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "350ee495"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os, ast, glob\n",
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ARitPNKV1Yrt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24616,
     "status": "ok",
     "timestamp": 1754760402964,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "ARitPNKV1Yrt",
    "outputId": "0ffc55f3-c361-420d-b840-d82a30deb1a6"
   },
   "outputs": [],
   "source": [
    "def find_repo_root(marker=\"setup.py\"):\n",
    "    path = Path.cwd()\n",
    "    while not (path / marker).exists() and path != path.parent:\n",
    "        path = path.parent\n",
    "    return path\n",
    "\n",
    "project_root = find_repo_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44bb077",
   "metadata": {
    "executionInfo": {
     "elapsed": 129,
     "status": "ok",
     "timestamp": 1754760403111,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "d44bb077"
   },
   "outputs": [],
   "source": [
    "# Original labels including A1, A2 (which were at index 31 and 32)\n",
    "channels_labels = [\n",
    "    \"Fp1\", \"Fp2\", \"F7\", \"F3\", \"Fz\", \"F4\", \"F8\", \"FC5\", \"FC1\", \"FC2\", \"FC6\", \"T7\",\n",
    "    \"C3\", \"C4\", \"T8\", \"TP9\", \"CP5\", \"CP1\", \"CP2\", \"CP6\", \"TP10\", \"P7\", \"P3\", \"Pz\",\n",
    "    \"P4\", \"P8\", \"O1\", \"Oz\", \"O2\", \"Iz\", \"AF7\", \"AF3\", \"AFz\", \"AF4\",\n",
    "    \"AF8\", \"F5\", \"F1\", \"F2\", \"F6\", \"FT7\", \"FC3\", \"FCz\", \"FC4\", \"FT8\", \"C5\", \"C1\",\n",
    "    \"C2\", \"C6\", \"TP7\", \"CP3\", \"CPz\", \"CP4\", \"TP8\", \"P5\", \"P1\", \"P2\", \"P6\", \"PO7\",\n",
    "    \"PO3\", \"POz\", \"PO4\", \"PO8\"\n",
    "]\n",
    "\n",
    "eeg_info = {\n",
    "    \"Fp1\": (\"Frontal pole\", \"attention, emotion, executive function\"),\n",
    "    \"Fp2\": (\"Frontal pole\", \"attention, emotion, executive function\"),\n",
    "    \"F7\": (\"Frontal\", \"language processing, auditory processing\"),\n",
    "    \"F3\": (\"Frontal\", \"working memory, decision making\"),\n",
    "    \"Fz\": (\"Frontal midline\", \"executive control, motor planning\"),\n",
    "    \"F4\": (\"Frontal\", \"working memory, decision making\"),\n",
    "    \"F8\": (\"Frontal\", \"language, auditory response\"),\n",
    "    \"FC5\": (\"Fronto-central\", \"speech perception, auditory-motor integration\"),\n",
    "    \"FC1\": (\"Fronto-central\", \"motor planning, decision making\"),\n",
    "    \"FC2\": (\"Fronto-central\", \"motor planning, decision making\"),\n",
    "    \"FC6\": (\"Fronto-central\", \"auditory-motor integration\"),\n",
    "    \"T7\": (\"Temporal\", \"primary auditory processing\"),\n",
    "    \"C3\": (\"Central\", \"motor cortex - movement of right side\"),\n",
    "    \"C4\": (\"Central\", \"motor cortex - movement of left side\"),\n",
    "    \"T8\": (\"Temporal\", \"auditory association\"),\n",
    "    \"TP9\": (\"Temporal-parietal\", \"sound localization, multisensory integration\"),\n",
    "    \"CP5\": (\"Centro-parietal\", \"sensorimotor integration\"),\n",
    "    \"CP1\": (\"Centro-parietal\", \"tactile processing, spatial attention\"),\n",
    "    \"CP2\": (\"Centro-parietal\", \"tactile processing, spatial attention\"),\n",
    "    \"CP6\": (\"Centro-parietal\", \"sensorimotor integration\"),\n",
    "    \"TP10\": (\"Temporal-parietal\", \"sound localization, multisensory integration\"),\n",
    "    \"P7\": (\"Parietal\", \"visual attention, spatial processing\"),\n",
    "    \"P3\": (\"Parietal\", \"spatial awareness, somatosensory integration\"),\n",
    "    \"Pz\": (\"Parietal midline\", \"visuospatial attention, awareness\"),\n",
    "    \"P4\": (\"Parietal\", \"spatial awareness, somatosensory integration\"),\n",
    "    \"P8\": (\"Parietal\", \"visual attention, spatial processing\"),\n",
    "    \"O1\": (\"Occipital\", \"primary visual cortex (left visual field)\"),\n",
    "    \"Oz\": (\"Occipital midline\", \"central visual processing\"),\n",
    "    \"O2\": (\"Occipital\", \"primary visual cortex (right visual field)\"),\n",
    "    \"Iz\": (\"Occipital\", \"visual association area\"),\n",
    "    \"A1\": (\"Reference electrode\", \"reference\"),\n",
    "    \"A2\": (\"Reference electrode\", \"reference\"),\n",
    "    \"AF7\": (\"Anterior frontal\", \"language and auditory attention\"),\n",
    "    \"AF3\": (\"Anterior frontal\", \"emotional control, working memory\"),\n",
    "    \"AFz\": (\"Anterior frontal midline\", \"conflict monitoring, executive control\"),\n",
    "    \"AF4\": (\"Anterior frontal\", \"emotional control, working memory\"),\n",
    "    \"AF8\": (\"Anterior frontal\", \"language and auditory attention\"),\n",
    "    \"F5\": (\"Frontal\", \"motor planning, cognitive control\"),\n",
    "    \"F1\": (\"Frontal\", \"executive function, motor planning\"),\n",
    "    \"F2\": (\"Frontal\", \"executive function, motor planning\"),\n",
    "    \"F6\": (\"Frontal\", \"motor planning, cognitive control\"),\n",
    "    \"FT7\": (\"Fronto-temporal\", \"auditory processing, speech perception\"),\n",
    "    \"FC3\": (\"Fronto-central\", \"motor preparation, sensorimotor integration\"),\n",
    "    \"FCz\": (\"Fronto-central midline\", \"motor control, attention\"),\n",
    "    \"FC4\": (\"Fronto-central\", \"motor preparation, sensorimotor integration\"),\n",
    "    \"FT8\": (\"Fronto-temporal\", \"auditory processing, speech perception\"),\n",
    "    \"C5\": (\"Central\", \"motor cortex - movement of right limbs\"),\n",
    "    \"C1\": (\"Central\", \"motor cortex - fine motor control (right)\"),\n",
    "    \"C2\": (\"Central\", \"motor cortex - fine motor control (left)\"),\n",
    "    \"C6\": (\"Central\", \"motor cortex - movement of left limbs\"),\n",
    "    \"TP7\": (\"Temporal-parietal\", \"speech and language integration\"),\n",
    "    \"CP3\": (\"Centro-parietal\", \"sensorimotor function, spatial processing\"),\n",
    "    \"CPz\": (\"Centro-parietal midline\", \"sensorimotor integration\"),\n",
    "    \"CP4\": (\"Centro-parietal\", \"sensorimotor function, spatial processing\"),\n",
    "    \"TP8\": (\"Temporal-parietal\", \"speech and language integration\"),\n",
    "    \"P5\": (\"Parietal\", \"visual attention, object recognition\"),\n",
    "    \"P1\": (\"Parietal\", \"visual spatial processing\"),\n",
    "    \"P2\": (\"Parietal\", \"visual spatial processing\"),\n",
    "    \"P6\": (\"Parietal\", \"visual attention, object recognition\"),\n",
    "    \"PO7\": (\"Parieto-occipital\", \"high-level visual processing\"),\n",
    "    \"PO3\": (\"Parieto-occipital\", \"visual integration, object recognition\"),\n",
    "    \"POz\": (\"Parieto-occipital midline\", \"visual attention and processing\"),\n",
    "    \"PO4\": (\"Parieto-occipital\", \"visual integration, object recognition\"),\n",
    "    \"PO8\": (\"Parieto-occipital\", \"high-level visual processing\")\n",
    "}\n",
    "\n",
    "function_map = {\n",
    "    \"visual\": [\"visual\", \"object recognition\", \"spatial\", \"association\", \"high-level\"],\n",
    "    \"auditory\": [\"auditory\", \"sound\"],\n",
    "    \"language\": [\"language\", \"speech\"],\n",
    "    \"motor\": [\"motor\", \"movement\", \"fine motor\"],\n",
    "    \"executive\": [\"executive\", \"decision\", \"working memory\", \"control\", \"conflict\"],\n",
    "    \"attention\": [\"attention\", \"focus\"],\n",
    "    \"sensorimotor\": [\"sensorimotor\", \"tactile\", \"somatosensory\"],\n",
    "    \"emotion\": [\"emotion\", \"emotional\"],\n",
    "}\n",
    "\n",
    "def get_original_index(modified_index):\n",
    "    return modified_index + 2 if modified_index >= 31 else modified_index\n",
    "\n",
    "def describe_eeg_channels(indices):\n",
    "    results = []\n",
    "    for idx in indices:\n",
    "        original_idx = get_original_index(idx)\n",
    "        label = channels_labels[original_idx]\n",
    "        region, modality = eeg_info.get(label, (\"Unknown region\", \"unknown\"))\n",
    "        results.append({\n",
    "            \"index\": idx,\n",
    "            \"original_label\": label,\n",
    "            \"brain_region\": region,\n",
    "            \"processing_type\": modality\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def map_processing_type(processing_str):\n",
    "    processing_str = processing_str.lower()\n",
    "    tags = set()\n",
    "    for group, keywords in function_map.items():\n",
    "        for kw in keywords:\n",
    "            if kw in processing_str:\n",
    "                tags.add(group)\n",
    "                break\n",
    "    return list(tags)\n",
    "\n",
    "# Parse a single Excel file\n",
    "def parse_subject_file(filepath):\n",
    "    df = pd.read_excel(filepath)\n",
    "    df['Net Nodes'] = df['Net Nodes'].apply(ast.literal_eval)\n",
    "    df['Processing Tags'] = df['Processing Type'].apply(map_processing_type)\n",
    "    return df\n",
    "\n",
    "# Process all Excel files in folder\n",
    "def process_all_subjects(data_folder='data'):\n",
    "    files = glob.glob(f\"{data_folder}/nets_*_S*_*.xlsx\")\n",
    "    all_networks = []\n",
    "\n",
    "    for file in files:\n",
    "        match = re.search(r'nets_(3down|23|12)_(S\\d+)_(\\d+)\\.xlsx', file)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        sigma, task, subject_id = match.groups()\n",
    "        subject_id = f\"sub{subject_id}\"\n",
    "        df = parse_subject_file(file)\n",
    "\n",
    "        # Temp dict to collect unique networks\n",
    "        net_dict = {}\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            key = (task, subject_id, row['Net Nodes'])\n",
    "            if key not in net_dict:\n",
    "                net_dict[key] = {\n",
    "                    'task': task,\n",
    "                    'subject': subject_id,\n",
    "                    'net_nodes': row['Net Nodes'],\n",
    "                    'pec': row['Last PEC Value'],\n",
    "                    'tags': set(row['Processing Tags']),\n",
    "                }\n",
    "            else:\n",
    "                net_dict[key]['tags'].update(row['Processing Tags'])\n",
    "\n",
    "        # Add unique entries to the result\n",
    "        for net in net_dict.values():\n",
    "            net['tags'] = sorted(net['tags'])  # optional\n",
    "            all_networks.append(net)\n",
    "\n",
    "    return all_networks\n",
    "\n",
    "# Summarize per subject and group\n",
    "def summarize_group(networks, top_n=3):\n",
    "    per_subject_summary = defaultdict(lambda: defaultdict(list))\n",
    "    group_tag_summary = defaultdict(list)\n",
    "\n",
    "    for net in networks:\n",
    "        subj = net['subject']\n",
    "        task = net['task']\n",
    "        key = f\"{subj}_{task}\"\n",
    "        per_subject_summary[key]['networks'].append(net)\n",
    "\n",
    "    per_subject_lowpec = {}\n",
    "    for key, data in per_subject_summary.items():\n",
    "        top_networks = sorted(data['networks'], key=lambda x: x['pec'])[:top_n]\n",
    "        tag_counter = defaultdict(int)\n",
    "\n",
    "        for net in top_networks:\n",
    "            for tag in net['tags']:\n",
    "                tag_counter[tag] += 1\n",
    "                group_tag_summary[tag].append(net['pec'])\n",
    "\n",
    "        per_subject_lowpec[key] = tag_counter\n",
    "\n",
    "    return per_subject_lowpec, group_tag_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00532d8",
   "metadata": {
    "id": "f00532d8"
   },
   "source": [
    "Check channel (node) functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f305dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1754760403198,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "f3f305dc",
    "outputId": "1a7a272c-be5a-4164-bf16-9b41bd47e64a"
   },
   "outputs": [],
   "source": [
    "# Generate node_functions from eeg_info\n",
    "node_functions = {}\n",
    "\n",
    "for idx, label in enumerate(channels_labels):\n",
    "    region, functions = eeg_info.get(label, (\"Unknown\", \"\"))\n",
    "    # Split the function string into a list of stripped keywords\n",
    "    function_keywords = [f.strip() for f in functions.split(\",\") if f.strip()]\n",
    "    node_functions[idx] = function_keywords\n",
    "\n",
    "print(\"Node functions:\", node_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ax8XhMgaQivS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1754760403419,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "ax8XhMgaQivS",
    "outputId": "b45ae1cc-470b-4810-c425-7f3317ca20bf"
   },
   "outputs": [],
   "source": [
    "# All functions considered\n",
    "function_weights = {\n",
    "    # General / always-on\n",
    "    'attention': 1,\n",
    "    'executive function': 2,\n",
    "    'working memory': 2,\n",
    "    'emotional control': 4,\n",
    "    'spatial awareness': 5,\n",
    "    'sensorimotor integration': 6,\n",
    "    'visual attention': 7,\n",
    "    'visual processing': 8,\n",
    "\n",
    "    # Visual task-specific\n",
    "    'primary visual cortex (left visual field)': 9,\n",
    "    'primary visual cortex (right visual field)': 10,\n",
    "    'visual spatial processing': 11,\n",
    "    'high-level visual processing': 12,\n",
    "    'object recognition': 13,\n",
    "    'visual integration': 14,\n",
    "\n",
    "    # Audio task-specific\n",
    "    'auditory-motor integration': 15,\n",
    "    'primary auditory processing': 16,\n",
    "    'speech perception': 17,\n",
    "    'speech and language integration': 18,\n",
    "    'language': 19,\n",
    "    'language processing': 20,\n",
    "    'sound localization': 21,\n",
    "    'auditory association': 22,\n",
    "    'auditory processing': 23,\n",
    "\n",
    "    # Other\n",
    "    'motor planning': 24,\n",
    "    'motor cortex - movement of left limbs': 25,\n",
    "    'motor cortex - movement of right limbs': 26,\n",
    "    'spatial processing': 27,\n",
    "    'conflict monitoring': 28,\n",
    "    'decision making': 29,\n",
    "    'emotional regulation': 30,\n",
    "    'tactile processing': 31,\n",
    "}\n",
    "\n",
    "def generate_function_map(eeg_info, function_weights):\n",
    "    function_map = defaultdict(list)\n",
    "    for ch, (_, functions_str) in eeg_info.items():\n",
    "        for function in function_weights:\n",
    "            # Match by substring (case-insensitive)\n",
    "            if function.lower() in functions_str.lower():\n",
    "                function_map[function].append(ch)\n",
    "    return dict(function_map)\n",
    "\n",
    "FUNCTION_MAP = generate_function_map(eeg_info, function_weights)\n",
    "print(FUNCTION_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99f6ebd",
   "metadata": {
    "id": "c99f6ebd"
   },
   "source": [
    "Define path to the network files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54994243",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78485,
     "status": "ok",
     "timestamp": 1754760482167,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "54994243",
    "outputId": "bc49e2b2-0274-43b0-a721-beae4e6164d9"
   },
   "outputs": [],
   "source": [
    "output_folder = project_root/\"nets\"\n",
    "figures_folder = project_root\n",
    "\n",
    "all_networks = process_all_subjects(data_folder=output_folder)\n",
    "print(f\"Found {len(all_networks)} total networks across all files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ul4QVPZg-NR7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783
    },
    "executionInfo": {
     "elapsed": 592,
     "status": "ok",
     "timestamp": 1753861214546,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "ul4QVPZg-NR7",
    "outputId": "1654f9c4-7be8-4a9d-bd78-1bcb94283bec"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro, ttest_ind, mannwhitneyu\n",
    "from itertools import combinations\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Prepare DataFrame\n",
    "df = pd.DataFrame(all_networks)\n",
    "\n",
    "# Order tasks\n",
    "task_order = ['S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7']\n",
    "df['task'] = pd.Categorical(df['task'], categories=task_order, ordered=True)\n",
    "\n",
    "# Test for normality (Shapiro-Wilk)\n",
    "normality = {}\n",
    "for task in task_order:\n",
    "    pec_vals = df[df['task'] == task]['pec']\n",
    "    if len(pec_vals) >= 3:  # Shapiro-Wilk requires at least 3 samples\n",
    "        stat, p = shapiro(pec_vals)\n",
    "        normality[task] = (p > 0.05)\n",
    "    else:\n",
    "        normality[task] = False\n",
    "\n",
    "# Pairwise comparisons\n",
    "comparisons = []\n",
    "pvals = []\n",
    "for task1, task2 in combinations(task_order, 2):\n",
    "    group1 = df[df['task'] == task1]['pec']\n",
    "    group2 = df[df['task'] == task2]['pec']\n",
    "\n",
    "    if normality[task1] and normality[task2]:\n",
    "        stat, p = ttest_ind(group1, group2, equal_var=False)\n",
    "        test = 't-test'\n",
    "    else:\n",
    "        stat, p = mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "        test = 'MWU'\n",
    "\n",
    "    comparisons.append((task1, task2, test))\n",
    "    pvals.append(p)\n",
    "\n",
    "# Apply Bonferroni correction\n",
    "_, pvals_corrected, _, _ = multipletests(pvals, method='bonferroni')\n",
    "significant = [(a, b, p) for (a, b, _), p in zip(comparisons, pvals_corrected) if p < 0.05]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.boxplot(x='task', y='pec', data=df, color='lightgrey')\n",
    "# sns.stripplot(x='task', y='pec', data=df, color='black', alpha=0.6, jitter=True)\n",
    "\n",
    "# Annotation helper\n",
    "def add_sig_annotation(ax, x1, x2, y, h, pval):\n",
    "    barx = [x1, x1, x2, x2]\n",
    "    bary = [y, y+h, y+h, y]\n",
    "    ax.plot(barx, bary, color='black', linewidth=1)\n",
    "    if pval < 0.001:\n",
    "        stars = '***'\n",
    "    elif pval < 0.01:\n",
    "        stars = '**'\n",
    "    else:\n",
    "        stars = '*'\n",
    "    ax.text((x1 + x2) * .5, y + h + 0.002, stars, ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# Add significance annotations\n",
    "y_max = df['pec'].max()\n",
    "height = (y_max) * 0.05\n",
    "offset = 0\n",
    "for task1, task2, pval in significant:\n",
    "    x1, x2 = task_order.index(task1), task_order.index(task2)\n",
    "    y = y_max + offset\n",
    "    add_sig_annotation(ax, x1, x2, y, height, pval)\n",
    "    offset += height * 1.5  # vertical spacing between lines\n",
    "\n",
    "# Labels\n",
    "plt.title(\"PEC Value Distribution Across Tasks (Subject: sub16)\", fontsize=16)\n",
    "plt.xlabel(\"Task\", fontsize=14)\n",
    "plt.ylabel(\"PEC\", fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p1O8QodaBIYt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 10472,
     "status": "ok",
     "timestamp": 1753857324826,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "p1O8QodaBIYt",
    "outputId": "37687ea0-68f2-4b84-dab0-63dfe9ab3ef3"
   },
   "outputs": [],
   "source": [
    "for i in range(1,25):\n",
    "  subject_id = f\"sub{i}\"\n",
    "  subject_networks = [net for net in all_networks if net[\"subject\"] == subject_id]\n",
    "\n",
    "  # Convert list of dictionaries to DataFrame\n",
    "  df = pd.DataFrame(subject_networks)\n",
    "\n",
    "  task_order = ['S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7']\n",
    "  df['task'] = pd.Categorical(df['task'], categories=task_order, ordered=True)\n",
    "\n",
    "  # Plot boxplot of PEC values per task\n",
    "  plt.figure(figsize=(10, 6))\n",
    "  sns.boxplot(x='task', y='pec', data=df, color=\"lightgrey\")\n",
    "  sns.stripplot(x='task', y='pec', data=df, color='black', alpha=0.6, jitter=True)\n",
    "\n",
    "  plt.title(f\"Distribution of PEC Values per Task\\nSubject {i}\", fontsize=16)\n",
    "  plt.xlabel(\"Task\", fontsize=14)\n",
    "  plt.ylabel(\"PEC\", fontsize=14)\n",
    "  plt.xticks(fontsize=12)\n",
    "  plt.yticks(fontsize=12)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9BaMP68H5zWJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5014,
     "status": "ok",
     "timestamp": 1753858686668,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "9BaMP68H5zWJ",
    "outputId": "f3a38576-3754-44d4-9152-2d05f8159e69"
   },
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "for i in range(1,25):\n",
    "  subject_id = f\"sub{i}\"\n",
    "  subject_networks = [net for net in all_networks if net[\"subject\"] == subject_id]\n",
    "\n",
    "  # Convert list of dictionaries to DataFrame\n",
    "  df = pd.DataFrame(subject_networks)\n",
    "\n",
    "  # Count number of networks per class (task S1–S7)\n",
    "  task_distribution = df['task'].value_counts().sort_index()\n",
    "\n",
    "  # Print or visualize\n",
    "  print(\"Number of networks per task:\")\n",
    "  print(task_distribution)\n",
    "\n",
    "  # Plot boxplot of PEC values per task\n",
    "  plt.figure(figsize=(10, 6))\n",
    "  sns.barplot(task_distribution, color='lightgrey')\n",
    "  plt.title(f\"Number of Networks per Task\\nSubject {i}\", fontsize=16)\n",
    "  plt.xlabel(\"Task\", fontsize=14)\n",
    "  plt.ylabel(\"Number of Networks\", fontsize=14)\n",
    "  plt.xticks(fontsize=12)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f0cf8",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1754760482170,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "351f0cf8"
   },
   "outputs": [],
   "source": [
    "def load_subject(id=1, data_folder=output_folder):\n",
    "    \"\"\"\n",
    "    Load all networks for a single subject, ensuring data exists for all tasks S1–S7.\n",
    "\n",
    "    Parameters:\n",
    "    - id (int): Subject ID to load.\n",
    "    - data_folder (str): Path to folder containing the .xlsx network files.\n",
    "\n",
    "    Returns:\n",
    "    - all_networks (list of dicts): Each dict has keys: subject, task, net_nodes, pec, tags.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError if any of the tasks (S1–S7) are missing.\n",
    "    \"\"\"\n",
    "    expected_tasks = {f\"S{i}\" for i in range(1, 7)}\n",
    "    all_networks = []\n",
    "    found_tasks = set()\n",
    "\n",
    "    pattern = re.compile(r'nets_(3down|23|12)_(S\\d+)_(\\d+)\\.xlsx$')\n",
    "    files = glob.glob(os.path.join(data_folder, f\"nets_*_S*_{id}.xlsx\"))\n",
    "\n",
    "    for file in files:\n",
    "        match = pattern.search(file)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        sigma, task, subject_id = match.groups()\n",
    "        found_tasks.add(task)\n",
    "\n",
    "        subject_id = f\"subj{subject_id}\"\n",
    "        df = parse_subject_file(file)\n",
    "\n",
    "        # Temp dict to collect unique networks\n",
    "        net_dict = {}\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            key = (task, subject_id, row['Net Nodes'])\n",
    "            if key not in net_dict:\n",
    "                net_dict[key] = {\n",
    "                    'task': task,\n",
    "                    'subject': subject_id,\n",
    "                    'net_nodes': row['Net Nodes'],\n",
    "                    'pec': row['Last PEC Value'],\n",
    "                    'tags': set(row['Processing Tags']),\n",
    "                }\n",
    "            else:\n",
    "                net_dict[key]['tags'].update(row['Processing Tags'])\n",
    "\n",
    "        # Add unique entries to the result\n",
    "        for net in net_dict.values():\n",
    "            net['tags'] = sorted(net['tags'])  # optional\n",
    "            all_networks.append(net)\n",
    "\n",
    "    # Check if all required tasks are present\n",
    "    missing_tasks = expected_tasks - found_tasks\n",
    "    if missing_tasks:\n",
    "        raise ValueError(f\"Subject {id} is missing data for task(s): {', '.join(sorted(missing_tasks))}\")\n",
    "\n",
    "    return all_networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kv24-aAthMlV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2857,
     "status": "ok",
     "timestamp": 1753873235687,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "Kv24-aAthMlV",
    "outputId": "4e5327b8-9e4a-43f0-9172-2306b996ef23"
   },
   "outputs": [],
   "source": [
    "def label_node(node_id):\n",
    "    funcs = node_functions.get(node_id, [])\n",
    "    return f\"{channels_labels[node_id]} ({', '.join(funcs)})\" if funcs else str(node_id)\n",
    "\n",
    "sub1 = load_subject(id=4)\n",
    "print(sub1[0])\n",
    "\n",
    "# Step 1: Find the minimum pec per task\n",
    "min_pec_per_task = defaultdict(lambda: float('inf'))\n",
    "\n",
    "for net in sub1:\n",
    "    task = net['task']\n",
    "    pec = net['pec']\n",
    "    if pec < min_pec_per_task[task]:\n",
    "        min_pec_per_task[task] = pec\n",
    "\n",
    "# Step 2: Filter sub1 to keep only nets with lowest pec per task\n",
    "best_nets_sub1 = [\n",
    "    net for net in sub1\n",
    "    if net['pec'] == min_pec_per_task[net['task']]\n",
    "]\n",
    "\n",
    "# Step 1: Count node occurrences per task\n",
    "task_node_counts = defaultdict(Counter)\n",
    "task_network_counts = Counter()  # Counts number of networks per task\n",
    "\n",
    "for net in sub1:\n",
    "    task = net['task']\n",
    "    nodes = net['net_nodes']\n",
    "    task_node_counts[task].update(nodes)\n",
    "    task_network_counts[task] += 1\n",
    "\n",
    "# Step 2: Create frequency DataFrame (nodes × tasks)\n",
    "all_nodes = sorted({node for counter in task_node_counts.values() for node in counter})\n",
    "task_list = sorted(task_node_counts.keys())\n",
    "\n",
    "freq_df = pd.DataFrame(index=all_nodes, columns=task_list).fillna(0)\n",
    "\n",
    "for task in task_list:\n",
    "    for node, count in task_node_counts[task].items():\n",
    "        freq_df.at[node, task] = count\n",
    "\n",
    "# # Normalize by number of networks per task\n",
    "# for task in task_list:\n",
    "#     freq_df[task] /= task_network_counts[task]\n",
    "\n",
    "# Step 3: Plot frequency heatmap\n",
    "plt.figure(figsize=(10, len(freq_df) * 0.3))\n",
    "ax = sns.heatmap(freq_df, annot=False, cmap='YlOrRd', linewidths=0.5)\n",
    "plt.title(\"Node Frequency Across Tasks\", fontsize=14)\n",
    "plt.xlabel(\"Task\")\n",
    "plt.ylabel(\"Node\")\n",
    "\n",
    "ytick_labels = [\n",
    "    f\"{channels_labels[node]} ({', '.join(node_functions.get(node, []))})\"\n",
    "    for node in freq_df.index]\n",
    "ax.set_yticks(np.arange(len(freq_df)) + 0.5)\n",
    "ax.set_yticklabels(ytick_labels, fontsize=9, rotation=0, va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Shared nodes across all tasks\n",
    "task_sets = {task: set(counter.keys()) for task, counter in task_node_counts.items()}\n",
    "shared_across_all = set.intersection(*task_sets.values())\n",
    "print(f\"Nodes shared across all tasks: {sorted(shared_across_all)}\")\n",
    "for node in sorted(shared_across_all):\n",
    "    funcs = \", \".join(node_functions.get(node, []))\n",
    "    print(f\"  {channels_labels[node]}: ({funcs})\")\n",
    "\n",
    "# Step 5: Pairwise shared nodes\n",
    "pairwise_shared_nodes = {}\n",
    "\n",
    "for task1, task2 in combinations(task_sets.keys(), 2):\n",
    "    shared = task_sets[task1].intersection(task_sets[task2])\n",
    "    pairwise_shared_nodes[(task1, task2)] = shared\n",
    "    print(f\"{task1} ∩ {task2}: {sorted(shared)} (n={len(shared)})\")\n",
    "\n",
    "# Step 6: Plot pairwise shared node count matrix\n",
    "shared_count_matrix = pd.DataFrame(index=task_list, columns=task_list).fillna(0)\n",
    "\n",
    "for (t1, t2), shared in pairwise_shared_nodes.items():\n",
    "    shared_count = len(shared)\n",
    "    shared_count_matrix.loc[t1, t2] = shared_count\n",
    "    shared_count_matrix.loc[t2, t1] = shared_count\n",
    "\n",
    "# Diagonal: total unique nodes per task\n",
    "for task in task_list:\n",
    "    shared_count_matrix.loc[task, task] = len(task_sets[task])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(shared_count_matrix.astype(int), annot=True, cmap=\"BuGn\", fmt='d')\n",
    "plt.title(\"Shared Node Counts Between Task Pairs\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "jaccard_matrix = pd.DataFrame(index=task_order, columns=task_order).fillna(0)\n",
    "bin_df = freq_df > 0\n",
    "\n",
    "for t1, t2 in combinations(task_order, 2):\n",
    "    score = jaccard_score(bin_df[t1], bin_df[t2])\n",
    "    jaccard_matrix.loc[t1, t2] = score\n",
    "    jaccard_matrix.loc[t2, t1] = score\n",
    "\n",
    "# Convert to float for heatmap\n",
    "jaccard_matrix = jaccard_matrix.astype(float)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(jaccard_matrix, annot=True, cmap='Blues', vmin=0, vmax=1, square=True)\n",
    "plt.title(\"Jaccard Similarity Between Task Node Sets\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Task-specific nodes\n",
    "print(\"\\nTask-Specific Nodes\")\n",
    "all_tasks = set(task_sets.keys())\n",
    "\n",
    "# For each task, subtract union of all other tasks' nodes\n",
    "for task in task_list:\n",
    "    other_tasks = all_tasks - {task}\n",
    "    other_nodes = set.union(*(task_sets[t] for t in other_tasks))\n",
    "    task_specific = task_sets[task] - other_nodes\n",
    "\n",
    "    print(f\"\\nTask {task} has {len(task_specific)} task-specific node(s)\")\n",
    "    for node in sorted(task_specific):\n",
    "        funcs = \", \".join(node_functions.get(node, []))\n",
    "        print(f\"  {channels_labels[node]}: ({funcs})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0762e",
   "metadata": {
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1754760482240,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "2ce0762e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "def plot_function_heatmap(df, plot_title=\"Function Contributions Across Networks\", results_path=Path(\"classification_clustering_reports\")):\n",
    "    subject = df.index[0].split('_')[0]\n",
    "    results_path.mkdir(exist_ok=True)\n",
    "\n",
    "    # Transpose for heatmap\n",
    "    data = df.T\n",
    "\n",
    "    # Remove functions (rows) with all zeros\n",
    "    data = data.loc[~(data == 0).all(axis=1)]\n",
    "\n",
    "    # Sort functions by predefined order\n",
    "    ordered_functions = [f for f in function_weights if f in data.index]\n",
    "    data_plot = data.loc[ordered_functions]\n",
    "\n",
    "    # Create heatmap figure\n",
    "    fig, ax = plt.subplots(figsize=(min(0.3 * len(data_plot.columns), 40), 12))\n",
    "    sns.heatmap(\n",
    "        data_plot,\n",
    "        cmap=\"mako\",\n",
    "        cbar_kws={'label': 'PEC-weighted score'},\n",
    "        ax=ax,\n",
    "        xticklabels=False,  # disable default xticks since you'll relabel\n",
    "        yticklabels=True\n",
    "    )\n",
    "\n",
    "    # Increase y-axis tick font size (function names)\n",
    "    ax.tick_params(axis='y', labelsize=22)\n",
    "\n",
    "    # Parse task labels (e.g., \"S1\", \"S2\")\n",
    "    task_labels = [idx.split('_')[1] for idx in df.index]\n",
    "\n",
    "    # Track start and end positions for each task\n",
    "    task_positions = {}\n",
    "    for i, task in enumerate(task_labels):\n",
    "        if task not in task_positions:\n",
    "            task_positions[task] = [i, i]\n",
    "        else:\n",
    "            task_positions[task][1] = i\n",
    "\n",
    "    # Clear default xticks\n",
    "    ax.set_xticks([])\n",
    "\n",
    "    # Map task codes to human-readable labels\n",
    "    task_label_map = {\n",
    "        'S1': 'A1',\n",
    "        'S2': 'A2',\n",
    "        'S3': 'A3',\n",
    "        'S4': 'V1',\n",
    "        'S5': 'V2',\n",
    "        'S6': 'V3',\n",
    "        'S7': 'R'\n",
    "    }\n",
    "\n",
    "    # Draw group labels under x-axis with mapped names\n",
    "    for task, (start, end) in task_positions.items():\n",
    "        label = task_label_map.get(task, task)\n",
    "        center = (start + end) / 2\n",
    "        ax.text(center + 0.5, len(data_plot.index) + 0.5, label,\n",
    "                ha='center', va='top', fontsize=20, rotation=0)\n",
    "\n",
    "        # Optional: Draw vertical line to separate task blocks\n",
    "        ax.add_patch(patches.Rectangle((start, 0), end - start + 1, len(data_plot.index),\n",
    "                                       linewidth=0.5, edgecolor='white', facecolor='none'))\n",
    "\n",
    "    # Set labels and title with larger font sizes\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Cognitive Functions\", labelpad=18, fontsize=22)\n",
    "    ax.set_title(plot_title, pad=25, fontsize=22)\n",
    "\n",
    "    # Set colorbar label font size\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    cbar.set_label(\"PEC-weighted score\", fontsize=22, labelpad=20)\n",
    "\n",
    "\n",
    "    # Save and show\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_path / f\"{subject}_vectors.pdf\", bbox_inches='tight')\n",
    "    plt.savefig(results_path / f\"{subject}_vectors.png\", bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WJQMFu7rs6eq",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1754760482173,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "WJQMFu7rs6eq"
   },
   "outputs": [],
   "source": [
    "def generate_function_vectors(networks, node_functions, function_weights, plot_type='heatmap'):\n",
    "    # Get all cognitive functions from the keys of function_weights\n",
    "    all_functions = sorted(function_weights.keys())\n",
    "\n",
    "    # Normalize PECs across all networks\n",
    "    all_pecs = [net['pec'] for net in networks]\n",
    "    max_pec = max(all_pecs)\n",
    "    min_pec = min(all_pecs)\n",
    "\n",
    "    def normalize_pec(pec):\n",
    "        return 1 - (pec - min_pec) / (max_pec - min_pec + 1e-6)\n",
    "\n",
    "    data = []\n",
    "    ids = []\n",
    "    s, i = 1, 0\n",
    "    for net in networks:\n",
    "        # Initialize a zero vector for all functions\n",
    "        vector = dict.fromkeys(all_functions, 0.0)\n",
    "\n",
    "        # Normalize this network's PEC\n",
    "        pec_weight = normalize_pec(net['pec'])\n",
    "\n",
    "        # Add PEC weight for all functions found in the network's nodes\n",
    "        for node in net['net_nodes']:\n",
    "            funcs = node_functions.get(node, [])\n",
    "            for f in funcs:\n",
    "                if f in vector:\n",
    "                    vector[f] += pec_weight\n",
    "\n",
    "        vec = [vector[f] for f in all_functions]\n",
    "        data.append(vec)\n",
    "\n",
    "        # Generate unique ID\n",
    "        if f\"{net['subject']}\" != f\"subj{s}\":\n",
    "            s += 1\n",
    "            i = 0\n",
    "        else:\n",
    "            i += 1\n",
    "        ids.append(f\"{net['subject']}_{net['task']}_{i}\")\n",
    "\n",
    "    df = pd.DataFrame(data, columns=all_functions, index=ids)\n",
    "\n",
    "    if plot_type == 'bar':\n",
    "        avg_weights = df.mean().sort_values(ascending=False)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x=avg_weights.values, y=avg_weights.index, palette=\"viridis\")\n",
    "        plt.title(\"Average PEC-weighted Function Contributions\")\n",
    "        plt.xlabel(\"Weighted Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    elif plot_type == 'heatmap':\n",
    "\n",
    "        # Sort columns (functions) by mean importance (descending)\n",
    "        df_plot = df.drop(columns=['other'], errors='ignore')\n",
    "        sorted_columns = df_plot.mean(axis=0).sort_values(ascending=False).index.tolist()\n",
    "\n",
    "        # Sort rows by subject and task and repetition\n",
    "        sorted_index = sorted(df_plot.index, key=lambda x: (x.split('_')[1], x.split('_')[0], int(x.split('_')[2])))\n",
    "\n",
    "        df_sorted = df_plot.loc[sorted_index, sorted_columns]\n",
    "\n",
    "        plot_function_heatmap(df_sorted)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdfc04b",
   "metadata": {
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1754760483248,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "bcdfc04b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, f1_score, accuracy_score,\n",
    "    precision_score, recall_score, roc_auc_score, average_precision_score)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set(style='whitegrid', context='talk')\n",
    "\n",
    "def preprocess_data(X, y_raw):\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y_raw)\n",
    "    y_classes = le.classes_\n",
    "    class_counts = pd.Series(y_raw).value_counts()\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    return X_scaled, y, y_classes, class_counts\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, f1_score, accuracy_score,\n",
    "    precision_score, recall_score, roc_auc_score, average_precision_score,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "sns.set(style='whitegrid', context='talk')\n",
    "\n",
    "\n",
    "def preprocess_data(X, y_raw):\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y_raw)\n",
    "    y_classes = le.classes_\n",
    "    class_counts = pd.Series(y_raw).value_counts()\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    return X_scaled, y, y_classes, class_counts\n",
    "\n",
    "\n",
    "def evaluate_classifier(X, y, class_names, subject_id=\"subject\", n_splits=5, plot=True, output_dir=\"results\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    from sklearn.exceptions import NotFittedError\n",
    "\n",
    "    class_counts = pd.Series(y).value_counts()\n",
    "    valid_classes = class_counts[class_counts >= n_splits].index.tolist()\n",
    "\n",
    "    if len(valid_classes) < 2:\n",
    "        raise ValueError(\"Not enough valid classes for classification after filtering.\")\n",
    "\n",
    "    valid_mask = np.isin(y, valid_classes)\n",
    "    X = X[valid_mask]\n",
    "    y = y[valid_mask]\n",
    "    label_map = {old: new for new, old in enumerate(sorted(valid_classes))}\n",
    "    y = np.array([label_map[yi] for yi in y])\n",
    "    class_names = [class_names[i] for i in sorted(valid_classes)]\n",
    "\n",
    "    print(f\"Including classes: {class_names}\")\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    clf = SVC(kernel='linear', probability=True, class_weight='balanced', random_state=42)\n",
    "\n",
    "    all_y_true, all_y_pred, all_y_proba = [], [], []\n",
    "    cm_total = np.zeros((len(class_names), len(class_names)))\n",
    "    all_coefs = []\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        try:\n",
    "            coefs = clf.coef_\n",
    "            all_coefs.append(coefs)\n",
    "        except NotFittedError:\n",
    "            print(\"Model not fitted, skipping coefficients.\")\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_proba = clf.predict_proba(X_test)\n",
    "\n",
    "        all_y_true.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        all_y_proba.extend(y_proba)\n",
    "        cm_total += confusion_matrix(y_test, y_pred, labels=np.arange(len(class_names)))\n",
    "\n",
    "    all_y_true = np.array(all_y_true)\n",
    "    all_y_pred = np.array(all_y_pred)\n",
    "    all_y_proba = np.array(all_y_proba)\n",
    "\n",
    "    # Metric Computation\n",
    "    y_true_bin = label_binarize(all_y_true, classes=np.arange(len(class_names)))\n",
    "\n",
    "    # Scores\n",
    "    report = classification_report(all_y_true, all_y_pred, target_names=class_names, output_dict=True)\n",
    "    f1 = f1_score(all_y_true, all_y_pred, average='weighted')\n",
    "    acc = accuracy_score(all_y_true, all_y_pred)\n",
    "    precision = precision_score(all_y_true, all_y_pred, average='weighted')\n",
    "    recall = recall_score(all_y_true, all_y_pred, average='weighted')\n",
    "    roc_auc_macro = roc_auc_score(y_true_bin, all_y_proba, average='macro', multi_class='ovr')\n",
    "    roc_auc_weighted = roc_auc_score(y_true_bin, all_y_proba, average='weighted', multi_class='ovr')\n",
    "    pr_auc_macro = average_precision_score(y_true_bin, all_y_proba, average='macro')\n",
    "    pr_auc_weighted = average_precision_score(y_true_bin, all_y_proba, average='weighted')\n",
    "\n",
    "    # Per-class ROC AUC and PR AUC\n",
    "    roc_auc_per_class = {}\n",
    "    pr_auc_per_class = {}\n",
    "\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        roc_auc_per_class[class_name] = roc_auc_score(y_true_bin[:, i], all_y_proba[:, i])\n",
    "        pr_auc_per_class[class_name] = average_precision_score(y_true_bin[:, i], all_y_proba[:, i])\n",
    "\n",
    "    # Append to report\n",
    "    metrics_df = pd.DataFrame(report).transpose()\n",
    "    metrics_df['support'] = metrics_df['support'].astype(int)\n",
    "\n",
    "    for class_name in class_names:\n",
    "        metrics_df.loc[class_name, 'roc_auc'] = roc_auc_per_class[class_name]\n",
    "        metrics_df.loc[class_name, 'pr_auc'] = pr_auc_per_class[class_name]\n",
    "\n",
    "    metrics_df.loc['weighted avg', 'roc_auc'] = roc_auc_weighted\n",
    "    metrics_df.loc['weighted avg', 'pr_auc'] = pr_auc_weighted\n",
    "\n",
    "    # Plotting Curves\n",
    "    if plot:\n",
    "        # ROC Curve\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            fpr, tpr, _ = roc_curve(y_true_bin[:, i], all_y_proba[:, i])\n",
    "            plt.plot(fpr, tpr, lw=2, label=f\"{class_name} (AUC = {roc_auc_per_class[class_name]:.2f})\")\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f\"Subject #{subject_id} ROC Curves\")\n",
    "        plt.legend(loc='lower right', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"{subject_id}_roc_curves.pdf\"))\n",
    "        plt.show()\n",
    "\n",
    "        # PR Curve\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            precision_i, recall_i, _ = precision_recall_curve(y_true_bin[:, i], all_y_proba[:, i])\n",
    "            plt.plot(recall_i, precision_i, lw=2, label=f\"{class_name} (AP = {pr_auc_per_class[class_name]:.2f})\")\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title(f\"Subject #{subject_id} Precision-Recall Curves\")\n",
    "        plt.legend(loc='upper right', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"{subject_id}_pr_curves.pdf\"))\n",
    "        plt.show()\n",
    "\n",
    "    # Feature Importance (mean coef)\n",
    "    if len(all_coefs) > 0:\n",
    "        all_coefs = np.array(all_coefs)\n",
    "        if all_coefs.ndim == 3:\n",
    "            avg_importance = np.mean(np.abs(all_coefs), axis=(0, 1))\n",
    "        else:\n",
    "            avg_importance = np.mean(np.abs(all_coefs), axis=0)\n",
    "    else:\n",
    "        avg_importance = np.zeros(X.shape[1])\n",
    "        print(\"Warning: No coefficients collected.\")\n",
    "\n",
    "    return (\n",
    "        metrics_df, cm_total, f1, acc, precision, recall,\n",
    "        roc_auc_weighted, pr_auc_weighted,\n",
    "        class_names, avg_importance\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_5qD9xKn3B48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14255,
     "status": "ok",
     "timestamp": 1754760497890,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "_5qD9xKn3B48",
    "outputId": "253d700e-c74e-4705-88fc-8ee455d37641"
   },
   "outputs": [],
   "source": [
    "output_dir = project_root/\"data/results/cnn/\"\n",
    "\n",
    "import builtins\n",
    "\n",
    "min = builtins.min\n",
    "max = builtins.max\n",
    "\n",
    "feature_importances = []\n",
    "\n",
    "for subject_id in range(1,25):\n",
    "    print(f\"\\nProcessing Subject {subject_id}\")\n",
    "    try:\n",
    "        # Load subject data\n",
    "        subject_data = load_subject(id=subject_id)\n",
    "        df_vectors = generate_function_vectors(subject_data, node_functions, function_weights, plot_type='heatmap')\n",
    "        # Preprocess\n",
    "        X = df_vectors.values\n",
    "        y_raw = [idx.split('_')[1] for idx in df_vectors.index]\n",
    "        X_scaled, y, y_classes, class_counts = preprocess_data(X, y_raw)\n",
    "\n",
    "        if len(np.unique(y)) < 2:\n",
    "            print(f\"Subject {subject_id}: Less than 2 classes present. Skipping.\")\n",
    "            continue\n",
    "        # Classify\n",
    "        metrics_df, cm_total, f1, acc, prec, rec, roc_auc, pr_auc, class_names, importances = evaluate_classifier(X_scaled, y, y_classes, subject_id=subject_id, plot=False)\n",
    "\n",
    "        feature_importances.append(importances)\n",
    "\n",
    "        metrics_df.to_csv(output_dir / f\"subject_{subject_id}_classification_metrics.csv\")\n",
    "        pd.DataFrame(cm_total, index=class_names, columns=class_names).to_csv(\n",
    "            output_dir / f\"subject_{subject_id}_confusion_matrix.csv\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Subject {subject_id} failed: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m97HRBGSf7lG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1A07NiHiVcKXUYkn39X5MZg2ZJyd3NdwE"
    },
    "executionInfo": {
     "elapsed": 147694,
     "status": "ok",
     "timestamp": 1754306733490,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "m97HRBGSf7lG",
    "outputId": "f465ecf8-f731-4318-9a1b-446415b660bf"
   },
   "outputs": [],
   "source": [
    "def group_labels(y_raw):\n",
    "    mapping = {\n",
    "        'S1': 'audio', 'S2': 'audio', 'S3': 'audio',\n",
    "        'S4': 'video', 'S5': 'video', 'S6': 'video',\n",
    "        'S7': 'rest'\n",
    "    }\n",
    "    y_grouped = [mapping[label] for label in y_raw]\n",
    "    return y_grouped\n",
    "\n",
    "import builtins\n",
    "min = builtins.min\n",
    "max = builtins.max\n",
    "\n",
    "feature_importances = []\n",
    "\n",
    "for subject_id in range(1,25):\n",
    "    print(f\"\\nProcessing Subject {subject_id}\")\n",
    "    try:\n",
    "        # Load subject data\n",
    "        subject_data = load_subject(id=subject_id)\n",
    "        df_vectors = generate_function_vectors(subject_data, node_functions, function_weights, plot_type='heatmap')\n",
    "        # Preprocess\n",
    "        X = df_vectors.values\n",
    "        y_raw = [idx.split('_')[1] for idx in df_vectors.index]\n",
    "\n",
    "        # Group the original labels into 3 classes\n",
    "        y_grouped = group_labels(y_raw)\n",
    "\n",
    "        # Preprocess with grouped labels\n",
    "        X_scaled, y, y_classes, class_counts = preprocess_data(X, y_grouped)\n",
    "\n",
    "\n",
    "        if len(np.unique(y)) < 2:\n",
    "            print(f\"Subject {subject_id}: Less than 2 classes present. Skipping.\")\n",
    "            continue\n",
    "        # Classify\n",
    "        metrics_df, cm_total, f1, acc, prec, rec, roc_auc, pr_auc, class_names, importances = evaluate_classifier(X_scaled, y, y_classes, subject_id=subject_id, plot=False)\n",
    "\n",
    "        feature_importances.append(importances)\n",
    "\n",
    "        metrics_df.to_csv(output_dir / f\"subject_{subject_id}_classification_metrics.csv\")\n",
    "        pd.DataFrame(cm_total, index=class_names, columns=class_names).to_csv(\n",
    "            output_dir / f\"subject_{subject_id}_confusion_matrix.csv\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Subject {subject_id} failed: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t953Cg8ljfOu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "executionInfo": {
     "elapsed": 1063,
     "status": "ok",
     "timestamp": 1754568247073,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "t953Cg8ljfOu",
    "outputId": "720a7f4c-2baa-4aaf-e63e-a46116fdd8df"
   },
   "outputs": [],
   "source": [
    "def plot_top_features(avg_importance, feature_names=None, top_n=20, title=\"Top Feature Importances\", save_path=None):\n",
    "    \"\"\"\n",
    "    Plot the top N most important features from averaged SVM coefficients.\n",
    "\n",
    "    Parameters:\n",
    "    - avg_importance (array-like): Importance values (e.g., mean of abs(coef_)).\n",
    "    - feature_names (list or None): List of actual feature labels. If None, uses F0, F1, ...\n",
    "    - top_n (int): Number of top features to show.\n",
    "    - title (str): Plot title.\n",
    "    - save_path (str or None): If provided, saves the figure to this path.\n",
    "    \"\"\"\n",
    "    # Default to generic feature labels if not provided\n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"F{i}\" for i in range(len(avg_importance))]\n",
    "\n",
    "    if len(feature_names) != len(avg_importance):\n",
    "        raise ValueError(\"Length of feature_names must match length of avg_importance.\")\n",
    "\n",
    "    # Create a DataFrame for easier sorting\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': avg_importance\n",
    "    })\n",
    "\n",
    "    # Select top N features by importance\n",
    "    top_df = importance_df.sort_values(by='Importance', ascending=False).head(top_n)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.barplot(data=top_df, x='Importance', y='Feature', palette='viridis')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Average Absolute Weight')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "feature_labels = df_vectors.columns.tolist()\n",
    "\n",
    "mean_importance = np.mean(feature_importances, axis=0)\n",
    "plot_top_features(mean_importance, feature_names=feature_labels, top_n=20, save_path=os.path.join(output_dir, \"feature_importances.pdf\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aFEQbcA72KFv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 9190,
     "status": "ok",
     "timestamp": 1754760507082,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "aFEQbcA72KFv",
    "outputId": "e6878ace-64e0-44e1-b825-7561e60d87e7"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro, levene, f_oneway, mannwhitneyu\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Paths and settings\n",
    "metrics_files = sorted(glob.glob(os.path.join(output_dir, \"subject_*_metrics.csv\")))\n",
    "\n",
    "ordered_classes = [f'S{i}' for i in range(1, 8)]\n",
    "task_labels = {\n",
    "    'S1': 'A1',\n",
    "    'S2': 'A2',\n",
    "    'S3': 'A3',\n",
    "    'S4': 'V1',\n",
    "    'S5': 'V2',\n",
    "    'S6': 'V3',\n",
    "    'S7': 'R'\n",
    "}\n",
    "custom_palette = {\n",
    "    'S1': '#a6dba0',\n",
    "    'S2': '#5aae61',\n",
    "    'S3': '#1b7837',\n",
    "    'S4': '#80cdc1',\n",
    "    'S5': '#4393c3',\n",
    "    'S6': '#2166ac',\n",
    "    'S7': '#bdbdbd'\n",
    "}\n",
    "\n",
    "# Load and filter data: only keep files with all classes S1-S7\n",
    "all_metrics = []\n",
    "for m_file in metrics_files:\n",
    "    df = pd.read_csv(m_file, index_col=0)\n",
    "    df = df.loc[~df.index.str.contains('avg|accuracy', case=False)]\n",
    "    present_classes = set(df.index.tolist())\n",
    "    if all(cls in present_classes for cls in ordered_classes):\n",
    "        all_metrics.append(df)\n",
    "\n",
    "# Combine and reshape data\n",
    "df_all_metrics = pd.concat(all_metrics)\n",
    "df_melted = df_all_metrics.reset_index().melt(\n",
    "    id_vars='index',\n",
    "    value_vars=['precision', 'recall', 'f1-score'],\n",
    "    var_name='Metric',\n",
    "    value_name='Score'\n",
    ")\n",
    "df_melted.rename(columns={'index': 'Class'}, inplace=True)\n",
    "df_melted['Task'] = df_melted['Class'].map(task_labels)\n",
    "df_melted['Color'] = df_melted['Class'].map(custom_palette)\n",
    "\n",
    "# Plot setup\n",
    "sns.set(style='whitegrid', context='talk')\n",
    "g = sns.catplot(\n",
    "    data=df_melted, kind='box',\n",
    "    x='Class', y='Score', col='Metric',\n",
    "    col_order=['precision', 'recall', 'f1-score'],\n",
    "    order=ordered_classes,\n",
    "    sharey=True, sharex=True,\n",
    "    height=6, aspect=1.2,\n",
    "    palette=custom_palette,\n",
    "    linewidth=1.2,\n",
    "    dodge=False,\n",
    "    showfliers=False\n",
    ")\n",
    "\n",
    "# Add jittered points, vertical lines, group titles, and labels\n",
    "for ax, metric in zip(g.axes[0], ['precision', 'recall', 'f1-score']):\n",
    "    subset = df_melted[df_melted['Metric'] == metric]\n",
    "\n",
    "    sns.stripplot(\n",
    "        data=subset, x='Class', y='Score', order=ordered_classes,\n",
    "        color='black', size=4, jitter=True, alpha=0.6, ax=ax\n",
    "    )\n",
    "\n",
    "    # Vertical group divider lines\n",
    "    ax.axvline(x=2.5, color='gray', linestyle='--', linewidth=1)\n",
    "    ax.axvline(x=5.5, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Group titles\n",
    "    ax.text(1, 1.03, 'Audiobook', ha='center', fontsize=14, color='#1b7837', weight='bold')\n",
    "    ax.text(4, 1.03, 'Video', ha='center', fontsize=14, color='#2166ac', weight='bold')\n",
    "    ax.text(6, 1.03, 'Rest', ha='center', fontsize=14, color='#555555', weight='bold')\n",
    "\n",
    "    ax.set_title(f'{metric.capitalize()}', pad=20)\n",
    "    ax.set_xlabel('Task')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_xticklabels([task_labels[c] for c in ordered_classes], rotation=45)\n",
    "\n",
    "# Function to convert p-values to stars\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001: return '***'\n",
    "    elif p < 0.01: return '**'\n",
    "    elif p < 0.05: return '*'\n",
    "    else: return ''\n",
    "\n",
    "# Statistical testing & annotation\n",
    "for ax, metric in zip(g.axes[0], ['precision', 'recall', 'f1-score']):\n",
    "    subset = df_melted[df_melted['Metric'] == metric]\n",
    "    groups = [subset[subset['Class'] == cls]['Score'].values for cls in ordered_classes]\n",
    "\n",
    "    # Check normality per group (Shapiro-Wilk)\n",
    "    normality_pvals = [shapiro(g)[1] if len(g) >= 3 else 1 for g in groups]\n",
    "    # Check homogeneity of variances (Levene)\n",
    "    lev_stat, lev_p = levene(*groups)\n",
    "\n",
    "    print(f\"\\n{metric} normality p-values per class:\", list(zip(ordered_classes, normality_pvals)))\n",
    "    print(f\"Levene test p-value: {lev_p:.4f}\")\n",
    "\n",
    "    if all(p > 0.05 for p in normality_pvals) and lev_p > 0.05:\n",
    "        print(f\"{metric}: Using ANOVA + Tukey\")\n",
    "        anova_stat, anova_p = f_oneway(*groups)\n",
    "        print(f\"ANOVA p-value: {anova_p:.4f}\")\n",
    "        sig_pairs = []\n",
    "        if anova_p <= 0.05:\n",
    "            tukey = pairwise_tukeyhsd(endog=subset['Score'], groups=subset['Class'], alpha=0.05)\n",
    "            for res in tukey.summary()[1:]:\n",
    "                g1 = str(res[0]).strip()\n",
    "                g2 = str(res[1]).strip()\n",
    "                p_adj = float(str(res[4]).strip())\n",
    "                reject = str(res[5]).strip() == 'True'\n",
    "                if reject:\n",
    "                    i = ordered_classes.index(g1)\n",
    "                    j = ordered_classes.index(g2)\n",
    "                    sig_pairs.append((i, j, p_adj))\n",
    "\n",
    "    else:\n",
    "        print(f\"{metric}: Using Mann-Whitney U tests\")\n",
    "        sig_pairs = []\n",
    "        for i in range(len(ordered_classes)):\n",
    "            for j in range(i + 1, len(ordered_classes)):\n",
    "                c1, c2 = ordered_classes[i], ordered_classes[j]\n",
    "                group1 = subset[subset['Class'] == c1]['Score'].values\n",
    "                group2 = subset[subset['Class'] == c2]['Score'].values\n",
    "                stat, p = mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "                if p < 0.05:\n",
    "                    sig_pairs.append((i, j, p))\n",
    "\n",
    "    # Annotate significant pairs on plot\n",
    "    # y_max = subset['Score'].max()\n",
    "    # h = 0.04  # height of bar\n",
    "    # text_offset = 0.01\n",
    "    # for i, j, p in sig_pairs:\n",
    "    #     y = y_max + h * (j - i) + text_offset\n",
    "    #     ax.plot([i, i, j, j], [y, y + h, y + h, y], c='k', lw=1.2)\n",
    "    #     ax.text((i + j) / 2, y + h, pval_to_stars(p), ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"per_class_boxplots_annotated.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print min, median, and max for each Class & Metric\n",
    "summary_stats = (\n",
    "    df_melted\n",
    "    .groupby(['Metric', 'Class'])['Score']\n",
    "    .agg(['min', 'median', 'max'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Map class codes to task labels for readability\n",
    "summary_stats['Task'] = summary_stats['Class'].map(task_labels)\n",
    "\n",
    "print(\"\\n=== Per-Class Boxplot Stats ===\")\n",
    "print(summary_stats.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ByJiFSwHc_T9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 776
    },
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1754568771915,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "ByJiFSwHc_T9",
    "outputId": "875f77f0-aa32-4639-88a3-61344f571db8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics_files = sorted(glob.glob(os.path.join(output_dir, \"subject_*_metrics.csv\")))\n",
    "\n",
    "# Collect weighted average metrics\n",
    "weighted_avgs = []\n",
    "\n",
    "for m_file in metrics_files:\n",
    "    df = pd.read_csv(m_file, index_col=0)\n",
    "    if 'weighted avg' in df.index:\n",
    "        row = df.loc['weighted avg']\n",
    "        weighted_avgs.append({\n",
    "            'Subject': os.path.basename(m_file).split(\"_\")[1],\n",
    "            'Precision': row.get('precision', None),\n",
    "            'Recall': row.get('recall', None),\n",
    "            'F1-score': row.get('f1-score', None),\n",
    "            'ROC-AUC': row.get('roc_auc', None),\n",
    "            'PR-AUC': row.get('pr_auc', None)\n",
    "        })\n",
    "\n",
    "df_weighted = pd.DataFrame(weighted_avgs)\n",
    "\n",
    "# Melt to long format for seaborn\n",
    "df_weighted_long = df_weighted.melt(id_vars='Subject', var_name='Metric', value_name='Score')\n",
    "\n",
    "# Plot all metrics together\n",
    "plt.figure(figsize=(7, 5.5))\n",
    "sns.boxplot(data=df_weighted_long, x='Metric', y='Score', linewidth=1.2, color='#bdbdbd')\n",
    "sns.stripplot(data=df_weighted_long, x='Metric', y='Score', color='black', size=5, jitter=True, alpha=0.6)\n",
    "\n",
    "plt.title('Weighted Average Metrics Across Subjects', fontsize=16)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"combined_weighted_metrics_boxplot.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Compute and print average and score range across subjects\n",
    "mean_scores = df_weighted.drop(columns='Subject').mean()\n",
    "print(\"Average weighted metrics across subjects:\\n\")\n",
    "for metric, score in mean_scores.items():\n",
    "    print(f\"{metric:>8}: {score:.4f}\")\n",
    "\n",
    "max_scores = df_weighted.drop(columns='Subject').max()\n",
    "min_scores = df_weighted.drop(columns='Subject').min()\n",
    "print(\"Score range across subjects:\\n\")\n",
    "for imin, imax in zip(min_scores.items(), max_scores.items()):\n",
    "    print(f\"{imin[0]:>8}: {imin[1]:.4f}, {imax[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_vYSDUrO3vOk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 926
    },
    "executionInfo": {
     "elapsed": 2000,
     "status": "ok",
     "timestamp": 1754568881388,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "_vYSDUrO3vOk",
    "outputId": "214d4594-791d-4c25-fc92-db4fce45b518"
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "task_labels = {\n",
    "    'S1': 'A1',\n",
    "    'S2': 'A2',\n",
    "    'S3': 'A3',\n",
    "    'S4': 'V1',\n",
    "    'S5': 'V2',\n",
    "    'S6': 'V3',\n",
    "    'S7': 'R'\n",
    "}\n",
    "\n",
    "# Set paths\n",
    "metrics_files = sorted(glob.glob(os.path.join(output_dir, \"subject_*_metrics.csv\")))\n",
    "conf_matrix_files = sorted(glob.glob(os.path.join(output_dir, \"subject_*_confusion_matrix.csv\")))\n",
    "\n",
    "all_metrics = []\n",
    "all_conf_matrices = []\n",
    "class_names = None\n",
    "\n",
    "# Load data\n",
    "for m_file, c_file in zip(metrics_files, conf_matrix_files):\n",
    "    df_metrics = pd.read_csv(m_file, index_col=0)\n",
    "    df_metrics = df_metrics.loc[~df_metrics.index.str.contains('avg|accuracy', case=False)]\n",
    "    all_metrics.append(df_metrics)\n",
    "\n",
    "    if class_names is None:\n",
    "        class_names = df_metrics.index.tolist()\n",
    "\n",
    "    cm = pd.read_csv(c_file, index_col=0).values\n",
    "    all_conf_matrices.append(cm)\n",
    "\n",
    "# Determine full class list\n",
    "all_classes = sorted(set(cls for df in all_metrics for cls in df.index))\n",
    "n_classes = len(all_classes)\n",
    "class_to_index = {cls: i for i, cls in enumerate(all_classes)}\n",
    "\n",
    "# Initialize accumulators\n",
    "weighted_sum_conf_matrix = np.zeros((n_classes, n_classes))\n",
    "row_weights = np.zeros((n_classes,))  # total samples per true class across all matrices\n",
    "\n",
    "# Process each subject's confusion matrix\n",
    "for df_metrics, cm_raw in zip(all_metrics, all_conf_matrices):\n",
    "    included_classes = df_metrics.index.tolist()\n",
    "    included_indices = [class_to_index[c] for c in included_classes]\n",
    "\n",
    "    cm_raw = cm_raw.astype(float)\n",
    "\n",
    "    # Compute row-wise sample counts (sum over rows)\n",
    "    row_sums = cm_raw.sum(axis=1)\n",
    "    row_sums[row_sums == 0] = 1  # avoid division by zero\n",
    "\n",
    "    # Row-normalize the matrix\n",
    "    cm_normalized = cm_raw / row_sums[:, np.newaxis]\n",
    "\n",
    "    # Update the full matrix with weights\n",
    "    for i, row_cls_idx in enumerate(included_indices):\n",
    "        n_samples = cm_raw[i].sum()\n",
    "        if n_samples == 0:\n",
    "            continue\n",
    "        for j, col_cls_idx in enumerate(included_indices):\n",
    "            weighted_sum_conf_matrix[row_cls_idx, col_cls_idx] += cm_normalized[i, j] * n_samples\n",
    "        row_weights[row_cls_idx] += n_samples\n",
    "\n",
    "# Final mean normalized confusion matrix\n",
    "mean_conf_matrix = np.divide(\n",
    "    weighted_sum_conf_matrix,\n",
    "    row_weights[:, np.newaxis],\n",
    "    out=np.zeros_like(weighted_sum_conf_matrix),\n",
    "    where=row_weights[:, np.newaxis] > 0\n",
    ")\n",
    "\n",
    "# Save and plot the result\n",
    "agg_cm_df = pd.DataFrame(mean_conf_matrix, index=all_classes, columns=all_classes)\n",
    "\n",
    "# Define the desired order and new labels\n",
    "# desired_order = ['audio', 'video', 'rest']\n",
    "# new_labels = ['Audio', 'Video', 'Rest']\n",
    "desired_order = ['S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7']\n",
    "new_labels = ['A1', 'A2', 'A3', 'V1', 'V2', 'V3', 'R']\n",
    "\n",
    "# Reorder the confusion matrix\n",
    "agg_cm_df = agg_cm_df.reindex(index=desired_order, columns=desired_order)\n",
    "\n",
    "agg_cm_df.to_csv(os.path.join(output_dir, \"aggregated_mean_normalized_confusion_matrix_weighted.csv\"))\n",
    "\n",
    "# Plot reordered and relabeled confusion matrix\n",
    "plt.figure(figsize=(8,7))\n",
    "sns.heatmap(agg_cm_df.values, annot=True, fmt=\".2f\",\n",
    "            xticklabels=new_labels, yticklabels=new_labels, cmap=\"YlGnBu\")\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "plt.title(\"Mean Normalized Confusion Matrix\", pad=10, size=18)\n",
    "plt.xlabel(\"Predicted\", size=18)\n",
    "plt.ylabel(\"True\", size=18)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(output_dir, \"mean_normalized_confusion_matrix_weighted.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Show most confused class pairs (off-diagonal only)\n",
    "conf_df = pd.DataFrame(mean_conf_matrix, index=all_classes, columns=all_classes)\n",
    "np.fill_diagonal(conf_df.values, 0)\n",
    "\n",
    "most_confused = conf_df.stack().sort_values(ascending=False)\n",
    "top_confusions = most_confused.head(10)\n",
    "\n",
    "print(\"\\nTop 10 Most Confused Class Pairs Across Subjects:\\n\")\n",
    "print(top_confusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MMlhhAR9orhh",
   "metadata": {
    "id": "MMlhhAR9orhh"
   },
   "outputs": [],
   "source": [
    "# EEG channel names by index\n",
    "eeg_channel_names = [\n",
    "    \"Fp1\", \"Fp2\", \"F7\", \"F3\", \"Fz\", \"F4\", \"F8\", \"FC5\", \"FC1\", \"FC2\", \"FC6\", \"T7\",\n",
    "    \"C3\", \"C4\", \"T8\", \"TP9\", \"CP5\", \"CP1\", \"CP2\", \"CP6\", \"TP10\", \"P7\", \"P3\", \"Pz\",\n",
    "    \"P4\", \"P8\", \"O1\", \"Oz\", \"O2\", \"Iz\", \"A1\", \"A2\", \"AF7\", \"AF3\", \"AFz\", \"AF4\",\n",
    "    \"AF8\", \"F5\", \"F1\", \"F2\", \"F6\", \"FT7\", \"FC3\", \"FCz\", \"FC4\", \"FT8\", \"C5\", \"C1\",\n",
    "    \"C2\", \"C6\", \"TP7\", \"CP3\", \"CPz\", \"CP4\", \"TP8\", \"P5\", \"P1\", \"P2\", \"P6\", \"PO7\",\n",
    "    \"PO3\", \"POz\", \"PO4\", \"PO8\"\n",
    "]\n",
    "\n",
    "def parse_networks(network_data):\n",
    "    true_labels = []\n",
    "    pec_values = []\n",
    "    list_of_graphs = []\n",
    "\n",
    "    for entry in network_data:\n",
    "        task = entry['task']\n",
    "        pec = entry['pec']\n",
    "        net_nodes = entry['net_nodes']\n",
    "        if task != \"S7\":\n",
    "          # Generate all pairwise edges (unordered)\n",
    "          edges = list(combinations(net_nodes, 2))\n",
    "\n",
    "          # Create node label dict (node index -> label string)\n",
    "          node_labels = {node: eeg_channel_names[node] for node in net_nodes}\n",
    "\n",
    "          graph = {\n",
    "              'edges': edges,\n",
    "              'node_labels': node_labels\n",
    "          }\n",
    "\n",
    "          true_labels.append(task)\n",
    "          pec_values.append(pec)\n",
    "          list_of_graphs.append(graph)\n",
    "\n",
    "    return true_labels, pec_values, list_of_graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XrbaNTBAosKB",
   "metadata": {
    "id": "XrbaNTBAosKB"
   },
   "outputs": [],
   "source": [
    "subject_data = load_subject(id=1)\n",
    "\n",
    "# network_data = best_nets_entry\n",
    "network_data = subject_data\n",
    "# network_data = all_networks\n",
    "\n",
    "true_labels, pec_values, list_of_graphs = parse_networks(network_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-4lsbMQfmz3N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 42607,
     "status": "ok",
     "timestamp": 1753860735796,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "-4lsbMQfmz3N",
    "outputId": "8c18fa89-23fe-468a-a808-a2d88f7404c3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering, DBSCAN\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "FUNCTION_MAP = {\n",
    "    'Visual Processing': [\n",
    "        \"O1\", \"O2\", \"Oz\", \"PO3\", \"PO4\", \"POz\", \"PO7\", \"PO8\"\n",
    "    ],\n",
    "    'Auditory Processing': [\n",
    "        \"T7\", \"T8\", \"TP7\", \"TP8\", \"FT7\", \"FT8\", \"TP9\", \"TP10\"\n",
    "    ],\n",
    "    'Language Processing': [\n",
    "        \"F7\", \"FC5\", \"FC3\", \"F3\", \"T7\", \"TP7\", \"CP5\"\n",
    "    ],\n",
    "    'Motor Control': [\n",
    "        \"C3\", \"C4\", \"Cz\", \"CP3\", \"CP4\", \"CPz\"\n",
    "    ],\n",
    "    'Executive Function / Attention': [\n",
    "        \"Fp1\", \"Fp2\", \"AF3\", \"AF4\", \"Fz\", \"F1\", \"F2\", \"F3\", \"F4\", \"F5\"\n",
    "    ],\n",
    "    'Somatosensory Processing': [\n",
    "        \"CP1\", \"CP2\", \"CP3\", \"CP4\", \"P1\", \"P2\", \"P3\", \"P4\"\n",
    "    ],\n",
    "    'Memory / Default Mode Network': [\n",
    "        \"Pz\", \"POz\", \"Oz\", \"Cz\", \"Fz\"\n",
    "    ],\n",
    "    'Emotion / Limbic': [\n",
    "        \"Fp1\", \"Fp2\", \"AF7\", \"AF8\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Improved feature extractor with normalized counts\n",
    "def func_normalized_counts(graph):\n",
    "    labels = graph['node_labels'].values()\n",
    "    counts = {f: 0 for f in FUNCTION_MAP}\n",
    "    for ch in labels:\n",
    "        for f, ch_list in FUNCTION_MAP.items():\n",
    "            if ch in ch_list:\n",
    "                counts[f] += 1\n",
    "    total_nodes = len(labels)\n",
    "    if total_nodes > 0:\n",
    "        norm_counts = [counts[f]/total_nodes for f in FUNCTION_MAP]\n",
    "    else:\n",
    "        norm_counts = [0]*len(FUNCTION_MAP)\n",
    "    return norm_counts\n",
    "\n",
    "# Extract normalized functional features for all graphs\n",
    "X_func = np.array([func_normalized_counts(g) for g in list_of_graphs])\n",
    "\n",
    "# Scale PEC values\n",
    "pec_scaled = MinMaxScaler().fit_transform(np.array(pec_values).reshape(-1, 1))\n",
    "\n",
    "# Interaction features: PEC * normalized functional counts (excluding node count)\n",
    "interaction = pec_scaled * X_func\n",
    "\n",
    "# Combine: normalized function features + node count + PEC + interactions\n",
    "X = np.hstack([pec_scaled, interaction])\n",
    "\n",
    "# Clustering algorithms to run\n",
    "clustering_algos = {\n",
    "    \"KMeans\": KMeans(n_clusters=6, random_state=42),\n",
    "    \"Agglomerative\": AgglomerativeClustering(n_clusters=6, linkage=\"average\"),\n",
    "    \"Spectral\": SpectralClustering(n_clusters=6, affinity='nearest_neighbors', n_neighbors=5, assign_labels='kmeans', random_state=42),\n",
    "}\n",
    "\n",
    "ari_scores = {}\n",
    "cluster_preds = {}\n",
    "\n",
    "for name, algo in clustering_algos.items():\n",
    "    preds = algo.fit_predict(X)\n",
    "    ari = adjusted_rand_score(true_labels, preds)\n",
    "    ari_scores[name] = ari\n",
    "    cluster_preds[name] = preds\n",
    "    print(f\"Silhouette score with {name}:\", silhouette_score(X, preds))\n",
    "\n",
    "print(\"Adjusted Rand Index (ARI) per Clustering Algorithm:\")\n",
    "for name, score in ari_scores.items():\n",
    "    print(f\"{name:<15}: {score:.3f}\")\n",
    "\n",
    "# Dimensionality reduction for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "X_umap = reducer.fit_transform(X)\n",
    "\n",
    "# Prepare DataFrame for plotting\n",
    "df = pd.DataFrame({\n",
    "    \"PC1\": X_pca[:,0],\n",
    "    \"PC2\": X_pca[:,1],\n",
    "    \"UMAP1\": X_umap[:,0],\n",
    "    \"UMAP2\": X_umap[:,1],\n",
    "    \"TrueLabel\": [str(t) for t in true_labels],\n",
    "    \"KMeans\": cluster_preds[\"KMeans\"],\n",
    "    \"Agglomerative\": cluster_preds[\"Agglomerative\"],\n",
    "    \"Spectral\": cluster_preds[\"Spectral\"],\n",
    "})\n",
    "\n",
    "# Plot PCA colored by true label and clusters\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.scatterplot(data=df, x=\"PC1\", y=\"PC2\", hue=\"TrueLabel\", palette=\"Set1\", s=60)\n",
    "plt.title(\"PCA Colored by True Label\")\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.scatterplot(data=df, x=\"PC1\", y=\"PC2\", hue=\"KMeans\", palette=\"Set2\", s=60)\n",
    "plt.title(\"PCA Colored by Clustering\")\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "# Plot UMAP colored by true label and clusters\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.scatterplot(data=df, x=\"UMAP1\", y=\"UMAP2\", hue=\"TrueLabel\", palette=\"Set1\", s=60)\n",
    "plt.title(\"UMAP Colored by True Label\")\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(data=df, x=\"UMAP1\", y=\"UMAP2\", hue=\"KMeans\", palette=\"Set2\", s=60)\n",
    "plt.title(\"UMAP Colored by Clustering\")\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zZWMZnN-yyzH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "executionInfo": {
     "elapsed": 803,
     "status": "ok",
     "timestamp": 1753860753715,
     "user": {
      "displayName": "KARLA IVANKOVIC",
      "userId": "00582019964017903949"
     },
     "user_tz": -120
    },
    "id": "zZWMZnN-yyzH",
    "outputId": "d6b6f7bb-2282-456f-bacf-534b8dc542fa"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Use cluster labels from Agglomerative clustering as pseudo-labels\n",
    "y_clusters = cluster_preds[\"Agglomerative\"]\n",
    "\n",
    "# Use original high-dimensional features (not PCA/UMAP) for feature importances\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y_clusters)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# --- Labeling features ---\n",
    "# Functional features (normalized node counts)\n",
    "func_feats = list(FUNCTION_MAP.keys())\n",
    "\n",
    "# PEC and interactions\n",
    "pec_feats = [\"PEC\"]\n",
    "interaction_feats = [f\"PEC*{f}\" for f in func_feats]\n",
    "\n",
    "# Final feature order (as used in X: PEC + interactions)\n",
    "feature_names = pec_feats + interaction_feats\n",
    "\n",
    "# Sanity check\n",
    "assert len(feature_names) == X.shape[1], \"Feature name count doesn't match input shape.\"\n",
    "\n",
    "# Create DataFrame\n",
    "feat_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feat_df.head(20), x=\"Importance\", y=\"Feature\", palette=\"viridis\")\n",
    "plt.title(\"Top 20 Feature Importances (Random Forest on Cluster Labels)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1hEhllMBaNLkJgeZP9S3JzCaYILQoJ0B7",
     "timestamp": 1751628640889
    }
   ]
  },
  "kernelspec": {
   "display_name": "xnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
