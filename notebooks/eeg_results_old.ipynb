{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ee495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os, ast, glob\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from multipec.simulation_utils import set_plotting_style\n",
    "\n",
    "def find_repo_root(marker=\"setup.py\"):\n",
    "    path = Path.cwd()\n",
    "    while not (path / marker).exists() and path != path.parent:\n",
    "        path = path.parent\n",
    "    return path\n",
    "\n",
    "project_root = find_repo_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44bb077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original labels including A1, A2 (which were at index 31 and 32)\n",
    "channels_labels = [\n",
    "    \"Fp1\", \"Fp2\", \"F7\", \"F3\", \"Fz\", \"F4\", \"F8\", \"FC5\", \"FC1\", \"FC2\", \"FC6\", \"T7\",\n",
    "    \"C3\", \"C4\", \"T8\", \"TP9\", \"CP5\", \"CP1\", \"CP2\", \"CP6\", \"TP10\", \"P7\", \"P3\", \"Pz\",\n",
    "    \"P4\", \"P8\", \"O1\", \"Oz\", \"O2\", \"Iz\", \"A1\", \"A2\", \"AF7\", \"AF3\", \"AFz\", \"AF4\",\n",
    "    \"AF8\", \"F5\", \"F1\", \"F2\", \"F6\", \"FT7\", \"FC3\", \"FCz\", \"FC4\", \"FT8\", \"C5\", \"C1\",\n",
    "    \"C2\", \"C6\", \"TP7\", \"CP3\", \"CPz\", \"CP4\", \"TP8\", \"P5\", \"P1\", \"P2\", \"P6\", \"PO7\",\n",
    "    \"PO3\", \"POz\", \"PO4\", \"PO8\"\n",
    "]\n",
    "\n",
    "eeg_info = {\n",
    "    \"Fp1\": (\"Frontal pole\", \"attention, emotion, executive function\"),\n",
    "    \"Fp2\": (\"Frontal pole\", \"attention, emotion, executive function\"),\n",
    "    \"F7\": (\"Frontal\", \"language processing, auditory processing\"),\n",
    "    \"F3\": (\"Frontal\", \"working memory, decision making\"),\n",
    "    \"Fz\": (\"Frontal midline\", \"executive control, motor planning\"),\n",
    "    \"F4\": (\"Frontal\", \"working memory, decision making\"),\n",
    "    \"F8\": (\"Frontal\", \"language, auditory response\"),\n",
    "    \"FC5\": (\"Fronto-central\", \"speech perception, auditory-motor integration\"),\n",
    "    \"FC1\": (\"Fronto-central\", \"motor planning, decision making\"),\n",
    "    \"FC2\": (\"Fronto-central\", \"motor planning, decision making\"),\n",
    "    \"FC6\": (\"Fronto-central\", \"auditory-motor integration\"),\n",
    "    \"T7\": (\"Temporal\", \"primary auditory processing\"),\n",
    "    \"C3\": (\"Central\", \"motor cortex - movement of right side\"),\n",
    "    \"C4\": (\"Central\", \"motor cortex - movement of left side\"),\n",
    "    \"T8\": (\"Temporal\", \"auditory association\"),\n",
    "    \"TP9\": (\"Temporal-parietal\", \"sound localization, multisensory integration\"),\n",
    "    \"CP5\": (\"Centro-parietal\", \"sensorimotor integration\"),\n",
    "    \"CP1\": (\"Centro-parietal\", \"tactile processing, spatial attention\"),\n",
    "    \"CP2\": (\"Centro-parietal\", \"tactile processing, spatial attention\"),\n",
    "    \"CP6\": (\"Centro-parietal\", \"sensorimotor integration\"),\n",
    "    \"TP10\": (\"Temporal-parietal\", \"sound localization, multisensory integration\"),\n",
    "    \"P7\": (\"Parietal\", \"visual attention, spatial processing\"),\n",
    "    \"P3\": (\"Parietal\", \"spatial awareness, somatosensory integration\"),\n",
    "    \"Pz\": (\"Parietal midline\", \"visuospatial attention, awareness\"),\n",
    "    \"P4\": (\"Parietal\", \"spatial awareness, somatosensory integration\"),\n",
    "    \"P8\": (\"Parietal\", \"visual attention, spatial processing\"),\n",
    "    \"O1\": (\"Occipital\", \"primary visual cortex (left visual field)\"),\n",
    "    \"Oz\": (\"Occipital midline\", \"central visual processing\"),\n",
    "    \"O2\": (\"Occipital\", \"primary visual cortex (right visual field)\"),\n",
    "    \"Iz\": (\"Occipital\", \"visual association area\"),\n",
    "    \"A1\": (\"Reference electrode\", \"reference\"),\n",
    "    \"A2\": (\"Reference electrode\", \"reference\"),\n",
    "    \"AF7\": (\"Anterior frontal\", \"language and auditory attention\"),\n",
    "    \"AF3\": (\"Anterior frontal\", \"emotional control, working memory\"),\n",
    "    \"AFz\": (\"Anterior frontal midline\", \"conflict monitoring, executive control\"),\n",
    "    \"AF4\": (\"Anterior frontal\", \"emotional control, working memory\"),\n",
    "    \"AF8\": (\"Anterior frontal\", \"language and auditory attention\"),\n",
    "    \"F5\": (\"Frontal\", \"motor planning, cognitive control\"),\n",
    "    \"F1\": (\"Frontal\", \"executive function, motor planning\"),\n",
    "    \"F2\": (\"Frontal\", \"executive function, motor planning\"),\n",
    "    \"F6\": (\"Frontal\", \"motor planning, cognitive control\"),\n",
    "    \"FT7\": (\"Fronto-temporal\", \"auditory processing, speech perception\"),\n",
    "    \"FC3\": (\"Fronto-central\", \"motor preparation, sensorimotor integration\"),\n",
    "    \"FCz\": (\"Fronto-central midline\", \"motor control, attention\"),\n",
    "    \"FC4\": (\"Fronto-central\", \"motor preparation, sensorimotor integration\"),\n",
    "    \"FT8\": (\"Fronto-temporal\", \"auditory processing, speech perception\"),\n",
    "    \"C5\": (\"Central\", \"motor cortex - movement of right limbs\"),\n",
    "    \"C1\": (\"Central\", \"motor cortex - fine motor control (right)\"),\n",
    "    \"C2\": (\"Central\", \"motor cortex - fine motor control (left)\"),\n",
    "    \"C6\": (\"Central\", \"motor cortex - movement of left limbs\"),\n",
    "    \"TP7\": (\"Temporal-parietal\", \"speech and language integration\"),\n",
    "    \"CP3\": (\"Centro-parietal\", \"sensorimotor function, spatial processing\"),\n",
    "    \"CPz\": (\"Centro-parietal midline\", \"sensorimotor integration\"),\n",
    "    \"CP4\": (\"Centro-parietal\", \"sensorimotor function, spatial processing\"),\n",
    "    \"TP8\": (\"Temporal-parietal\", \"speech and language integration\"),\n",
    "    \"P5\": (\"Parietal\", \"visual attention, object recognition\"),\n",
    "    \"P1\": (\"Parietal\", \"visual spatial processing\"),\n",
    "    \"P2\": (\"Parietal\", \"visual spatial processing\"),\n",
    "    \"P6\": (\"Parietal\", \"visual attention, object recognition\"),\n",
    "    \"PO7\": (\"Parieto-occipital\", \"high-level visual processing\"),\n",
    "    \"PO3\": (\"Parieto-occipital\", \"visual integration, object recognition\"),\n",
    "    \"POz\": (\"Parieto-occipital midline\", \"visual attention and processing\"),\n",
    "    \"PO4\": (\"Parieto-occipital\", \"visual integration, object recognition\"),\n",
    "    \"PO8\": (\"Parieto-occipital\", \"high-level visual processing\")\n",
    "}\n",
    "\n",
    "function_map = {\n",
    "    \"visual\": [\"visual\", \"object recognition\", \"spatial\", \"association\", \"high-level\"],\n",
    "    \"auditory\": [\"auditory\", \"sound\"],\n",
    "    \"language\": [\"language\", \"speech\"],\n",
    "    \"motor\": [\"motor\", \"movement\", \"fine motor\"],\n",
    "    \"executive\": [\"executive\", \"decision\", \"working memory\", \"control\", \"conflict\"],\n",
    "    \"attention\": [\"attention\", \"focus\"],\n",
    "    \"sensorimotor\": [\"sensorimotor\", \"tactile\", \"somatosensory\"],\n",
    "    \"emotion\": [\"emotion\", \"emotional\"],\n",
    "}\n",
    "\n",
    "def get_original_index(modified_index):\n",
    "    return modified_index + 2 if modified_index >= 31 else modified_index\n",
    "\n",
    "def describe_eeg_channels(indices):\n",
    "    results = []\n",
    "    for idx in indices:\n",
    "        original_idx = get_original_index(idx)\n",
    "        label = channels_labels[original_idx]\n",
    "        region, modality = eeg_info.get(label, (\"Unknown region\", \"unknown\"))\n",
    "        results.append({\n",
    "            \"index\": idx,\n",
    "            \"original_label\": label,\n",
    "            \"brain_region\": region,\n",
    "            \"processing_type\": modality\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def map_processing_type(processing_str):\n",
    "    processing_str = processing_str.lower()\n",
    "    tags = set()\n",
    "    for group, keywords in function_map.items():\n",
    "        for kw in keywords:\n",
    "            if kw in processing_str:\n",
    "                tags.add(group)\n",
    "                break\n",
    "    return list(tags)\n",
    "\n",
    "# Parse a single Excel file\n",
    "def parse_subject_file(filepath):\n",
    "    df = pd.read_excel(filepath)\n",
    "    df['Net Nodes'] = df['Net Nodes'].apply(ast.literal_eval)\n",
    "    df['Processing Tags'] = df['Processing Type'].apply(map_processing_type)\n",
    "    return df\n",
    "\n",
    "# Process all Excel files in folder\n",
    "def process_all_subjects(data_folder='data'):\n",
    "    files = glob.glob(f\"{data_folder}/nets_*_S*_*.xlsx\")\n",
    "    all_networks = []\n",
    "\n",
    "    for file in files:\n",
    "        match = re.search(r'nets_(3down|23|12)_(S\\d+)_(\\d+)\\.xlsx', file)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        sigma, task, subject_id = match.groups()\n",
    "        subject_id = f\"sub{subject_id}\"\n",
    "        df = parse_subject_file(file)\n",
    "\n",
    "        # Temp dict to collect unique networks\n",
    "        net_dict = {}\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            key = (task, subject_id, row['Net Nodes'])\n",
    "            if key not in net_dict:\n",
    "                net_dict[key] = {\n",
    "                    'task': task,\n",
    "                    'subject': subject_id,\n",
    "                    'net_nodes': row['Net Nodes'],\n",
    "                    'pec': row['Last PEC Value'],\n",
    "                    'tags': set(row['Processing Tags']),\n",
    "                }\n",
    "            else:\n",
    "                net_dict[key]['tags'].update(row['Processing Tags'])\n",
    "\n",
    "        # Add unique entries to the result\n",
    "        for net in net_dict.values():\n",
    "            net['tags'] = sorted(net['tags'])  # optional\n",
    "            all_networks.append(net)\n",
    "\n",
    "    return all_networks\n",
    "\n",
    "# Summarize per subject and group\n",
    "def summarize_group(networks, top_n=3):\n",
    "    per_subject_summary = defaultdict(lambda: defaultdict(list))\n",
    "    group_tag_summary = defaultdict(list)\n",
    "\n",
    "    for net in networks:\n",
    "        subj = net['subject']\n",
    "        task = net['task']\n",
    "        key = f\"{subj}_{task}\"\n",
    "        per_subject_summary[key]['networks'].append(net)\n",
    "\n",
    "    per_subject_lowpec = {}\n",
    "    for key, data in per_subject_summary.items():\n",
    "        top_networks = sorted(data['networks'], key=lambda x: x['pec'])[:top_n]\n",
    "        tag_counter = defaultdict(int)\n",
    "\n",
    "        for net in top_networks:\n",
    "            for tag in net['tags']:\n",
    "                tag_counter[tag] += 1\n",
    "                group_tag_summary[tag].append(net['pec'])\n",
    "\n",
    "        per_subject_lowpec[key] = tag_counter\n",
    "\n",
    "    return per_subject_lowpec, group_tag_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00532d8",
   "metadata": {},
   "source": [
    "Check channel (node) functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f305dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate node_functions from eeg_info\n",
    "node_functions = {}\n",
    "\n",
    "for idx, label in enumerate(channels_labels):\n",
    "    region, functions = eeg_info.get(label, (\"Unknown\", \"\"))\n",
    "    # Split the function string into a list of stripped keywords\n",
    "    function_keywords = [f.strip() for f in functions.split(\",\") if f.strip()]\n",
    "    node_functions[idx] = function_keywords\n",
    "\n",
    "print(\"Node functions:\", node_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99f6ebd",
   "metadata": {},
   "source": [
    "Define path to the network files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54994243",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = project_root/\"data/output/eeg/\"\n",
    "figures_folder = project_root/\"data/figures/eeg/\"\n",
    "os.makedirs(figures_folder, exist_ok=True)\n",
    "\n",
    "all_networks = process_all_subjects(data_folder=output_folder)\n",
    "print(f\"Found {len(all_networks)} total networks across all files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0401b56",
   "metadata": {},
   "source": [
    "Check which subjects are missing nets per task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83743f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_task_gaps_by_subject(directory, all_subjects=[str(i+1) for i in range(24)], tasks=['S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7']):\n",
    "    pattern = re.compile(r'nets_(3down|23|12)_(S\\d+)_(\\d+)\\.p$')\n",
    "    subject_tasks = defaultdict(set)\n",
    "    all_subjects = set(all_subjects)\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        match = re.search(r'nets_(3down|23|12)_(S\\d+)_(\\d+)\\.p', filename)\n",
    "        if match:\n",
    "            sigma, task, subject_id = match.groups()\n",
    "            subject_tasks[subject_id].add(task)\n",
    "\n",
    "    # Initialize a dict to collect missing subjects for each task\n",
    "    task_missing_subjects = defaultdict(list)\n",
    "\n",
    "    for subject_id in all_subjects:\n",
    "        for task in tasks:\n",
    "            if task not in subject_tasks[subject_id]:\n",
    "                task_missing_subjects[task].append(subject_id)\n",
    "\n",
    "    return task_missing_subjects\n",
    "\n",
    "missing_by_task = find_task_gaps_by_subject(output_folder)\n",
    "\n",
    "if missing_by_task:\n",
    "    for task, subjects in sorted(missing_by_task.items()):\n",
    "        if subjects:\n",
    "          print(f\"Task {task} is missing in subjects: {', '.join(map(str, sorted(subjects)))}\")\n",
    "\n",
    "else:\n",
    "    print(\"All tasks are available for all subjects.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbab1af4",
   "metadata": {},
   "source": [
    "Summarize the networks per task (per subject summary, and then group summary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998715f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_by_stimulus(all_networks, summarize_group_func, top_n=3):\n",
    "    \"\"\"\n",
    "    Summarize networks grouped by stimulus/task (S1, S2, ..., S7).\n",
    "\n",
    "    Parameters:\n",
    "    - all_networks: list of network dictionaries\n",
    "    - summarize_group_func: function to summarize a group (expects signature like summarize_group(networks, top_n))\n",
    "    - top_n: number of top functions/features to consider when summarizing\n",
    "\n",
    "    Prints:\n",
    "    - Per stimulus: per-subject summary and group-level summary\n",
    "    \"\"\"\n",
    "    # Group networks by stimulus type (e.g., S1, S2, ..., S7)\n",
    "    stimulus_groups = defaultdict(list)\n",
    "    for net in all_networks:\n",
    "        stimulus = net['task']  # assuming 'task' field like 'S1', 'S2', ...\n",
    "        stimulus_groups[stimulus].append(net)\n",
    "\n",
    "    # Summarize each stimulus group\n",
    "    for stim_type in sorted(stimulus_groups.keys()):\n",
    "        print(f\"\\nStimulus: {stim_type}\")\n",
    "        subject_summary, group_summary = summarize_group_func(stimulus_groups[stim_type], top_n=top_n)\n",
    "\n",
    "        print(\"Per Subject Summary:\")\n",
    "        for key, tag_counts in subject_summary.items():\n",
    "            print(f\"    {key}: {dict(tag_counts)}\")\n",
    "\n",
    "        print(\"Group Summary (Avg PEC per function):\")\n",
    "        for tag, pecs in group_summary.items():\n",
    "            mean_pec = sum(pecs)/len(pecs) if pecs else 0\n",
    "            print(f\"    {tag}: Mean PEC = {mean_pec:.4f}, Count = {len(pecs)}\")\n",
    "\n",
    "summarize_by_stimulus(all_networks, summarize_group, top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37dba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_plotting_style()\n",
    "\n",
    "def get_best_nets_by_subject(networks):\n",
    "    subject_stimulus_map = defaultdict(list)\n",
    "\n",
    "    # Group networks by (subject, task)\n",
    "    for net in networks:\n",
    "        key = (net['subject'], net['task'])\n",
    "        subject_stimulus_map[key].append(net)\n",
    "\n",
    "    best_nets = []\n",
    "\n",
    "    for (subject, stimulus), nets in subject_stimulus_map.items():\n",
    "        min_pec = min(net['pec'] for net in nets)\n",
    "        lowest_nets = [net for net in nets if net['pec'] == min_pec]\n",
    "\n",
    "        best_nets.extend(lowest_nets)\n",
    "\n",
    "    return best_nets\n",
    "\n",
    "# Get only best PEC networks per subject per stimulus\n",
    "best_networks = get_best_nets_by_subject(all_networks)\n",
    "\n",
    "# Group tags per stimulus type\n",
    "stimulus_tag_summary = defaultdict(list)\n",
    "for net in best_networks:\n",
    "    for tag in net['tags']:\n",
    "        stimulus_tag_summary[net['task']].append(tag)\n",
    "\n",
    "# Count and display tags per stimulus\n",
    "print(\"\\nBest Networks - Functional Tag Summary by Stimulus\")\n",
    "for stim_type in sorted(stimulus_tag_summary.keys()):\n",
    "    tag_counts = defaultdict(int)\n",
    "    for tag in stimulus_tag_summary[stim_type]:\n",
    "        tag_counts[tag] += 1\n",
    "    print(f\"\\nStimulus {stim_type}:\")\n",
    "    for tag, count in sorted(tag_counts.items(), key=lambda x: -x[1]):\n",
    "        print(f\"  {tag}: {count}\")\n",
    "\n",
    "# Plot bar plots for each stimulus\n",
    "def plot_tag_distributions(tag_summary):\n",
    "    num_stimuli = len(tag_summary)\n",
    "    fig, axs = plt.subplots(num_stimuli, 1, figsize=(10, 4 * num_stimuli))\n",
    "\n",
    "    if num_stimuli == 1:\n",
    "        axs = [axs] # Ensure axs is iterable\n",
    "\n",
    "    for ax, (stimulus, tags) in zip(axs, sorted(tag_summary.items())):\n",
    "        tag_counts = Counter(tags)\n",
    "        sorted_tags = sorted(tag_counts.items(), key=lambda x: -x[1])\n",
    "        labels, counts = zip(*sorted_tags)\n",
    "\n",
    "        ax.bar(labels, counts, color='skyblue', edgecolor='black')\n",
    "        ax.set_title(f\"Stimulus {stimulus} - Functional Tag Distribution\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the plotting function\n",
    "plot_tag_distributions(stimulus_tag_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b552c0",
   "metadata": {},
   "source": [
    "See PEC variation across tasks, per subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd09737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary: { subject: {stimulus: [best_net(s)] } }\n",
    "best_nets_by_subject = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for net in all_networks:\n",
    "    subj = net[\"subject\"]\n",
    "    stim = net[\"task\"]\n",
    "    pec = net[\"pec\"]\n",
    "\n",
    "    current_best = best_nets_by_subject[subj][stim]\n",
    "\n",
    "    if not current_best:\n",
    "        best_nets_by_subject[subj][stim] = [net]\n",
    "    else:\n",
    "        best_pec = current_best[0]['pec']\n",
    "        if pec < best_pec:\n",
    "            best_nets_by_subject[subj][stim] = [net]\n",
    "        elif pec == best_pec:\n",
    "            best_nets_by_subject[subj][stim].append(net)\n",
    "\n",
    "# Define stimulus groups\n",
    "group_a = ['S1', 'S2', 'S3', 'S7']\n",
    "group_b = ['S4', 'S5', 'S6', 'S7']\n",
    "\n",
    "def extract_min_pecs(best_nets_by_subject, group):\n",
    "    subj_pecs = defaultdict(list)\n",
    "\n",
    "    for subj, stim_dict in best_nets_by_subject.items():\n",
    "        for stim in group:\n",
    "            if stim in stim_dict:\n",
    "                min_pecs = [n['pec'] for n in stim_dict[stim]]\n",
    "                mean_min = np.mean(min_pecs)  # Handle ties\n",
    "                subj_pecs[subj].append((stim, mean_min))\n",
    "        subj_pecs[subj] = sorted(subj_pecs[subj], key=lambda x: group.index(x[0]))\n",
    "\n",
    "    return subj_pecs\n",
    "\n",
    "def plot_group_pec_trends(ax, subj_pecs, group, title):\n",
    "    x_ticks = list(range(len(group)))\n",
    "\n",
    "    for subj, data in subj_pecs.items():\n",
    "        if len(data) < 2:\n",
    "            continue\n",
    "        x = [group.index(stim) for stim, _ in data]\n",
    "        y = [pec for _, pec in data]\n",
    "        ax.plot(x, y, marker='o', alpha=0.4, label=subj, linewidth=1)\n",
    "\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels(group)\n",
    "    ax.set_xlabel(\"Stimulus\")\n",
    "    ax.set_ylabel(\"Min PEC\")\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True)\n",
    "\n",
    "subj_pecs_a = extract_min_pecs(best_nets_by_subject, group_a)\n",
    "subj_pecs_b = extract_min_pecs(best_nets_by_subject, group_b)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "plot_group_pec_trends(axes[0], subj_pecs_a, group_a, \"Group A (S1, S2, S3, S7)\")\n",
    "plot_group_pec_trends(axes[1], subj_pecs_b, group_b, \"Group B (S4, S5, S6, S7)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea49222",
   "metadata": {},
   "source": [
    "Count how many subjects have all data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad84e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_a_count = sum(len(data) == 4 for data in subj_pecs_a.values())\n",
    "group_b_count = sum(len(data) == 4 for data in subj_pecs_b.values())\n",
    "\n",
    "print(f\"Subjects in Group A (S1, S2, S3, S7): {group_a_count}\")\n",
    "print(f\"Subjects in Group B (S4, S5, S6, S7): {group_b_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566fae1e",
   "metadata": {},
   "source": [
    "Calculate PEC changes between S1 and S3; and S4 and S6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b6ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PEC changes between task pairs\n",
    "changes_data = []\n",
    "\n",
    "for subj, pec_values in best_nets_by_subject.items():\n",
    "    # Get the PEC values for each stimulus\n",
    "    pec_S1 = pec_values.get('S1')[0]['pec'] if pec_values.get('S1') else None\n",
    "    pec_S3 = pec_values.get('S3')[0]['pec'] if pec_values.get('S3') else None\n",
    "    pec_S4 = pec_values.get('S4')[0]['pec'] if pec_values.get('S4') else None\n",
    "    pec_S6 = pec_values.get('S6')[0]['pec'] if pec_values.get('S6') else None\n",
    "\n",
    "    if pec_S1 is not None and pec_S3 is not None:\n",
    "        # Calculate the PEC change for S2 vs S1\n",
    "        change_S3_S1 = pec_S3 - pec_S1\n",
    "        changes_data.append({'subject': subj, 'stimulus_group': 'S3-S1', 'change_value': change_S3_S1})\n",
    "\n",
    "    if pec_S4 is not None and pec_S6 is not None:\n",
    "        # Calculate the PEC change for S4 vs S5\n",
    "        change_S6_S4 = pec_S6 - pec_S4\n",
    "        changes_data.append({'subject': subj, 'stimulus_group': 'S6-S4', 'change_value': change_S6_S4})\n",
    "\n",
    "changes_df = pd.DataFrame(changes_data)\n",
    "\n",
    "# Calculate the 'direction' based on PEC change (positive or negative) between tasks\n",
    "changes_df['direction'] = changes_df['change_value'].apply(lambda x: 'positive' if x > 0 else 'negative')\n",
    "\n",
    "# Plot the count of positive and negative changes for each comparison\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.countplot(x='direction', hue='stimulus_group', data=changes_df)\n",
    "plt.title('Change in PEC across Tasks')\n",
    "plt.xlabel('Change Direction')\n",
    "plt.ylabel('Number of Subjects')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a71a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def test_classifiers_on_tasks(best_networks, selected_tasks, all_nodes=[i for i in range(62)]):\n",
    "    # 1. Filter networks to selected tasks only\n",
    "    filtered_nets = [net for net in best_networks if net['task'] in selected_tasks]\n",
    "\n",
    "    # 3. Create feature matrix\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for net in filtered_nets:\n",
    "        node_set = set(net['net_nodes'])\n",
    "        feature_vector = [1 if node in node_set else 0 for node in all_nodes]\n",
    "        X.append(feature_vector)\n",
    "        y.append(net['task'])\n",
    "\n",
    "    # 4. Encode class labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 5. Define classifiers\n",
    "    classifiers = {\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"SVM (Linear Kernel)\": SVC(kernel='linear', probability=True, random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "    }\n",
    "\n",
    "    # 6. Run and evaluate each classifier\n",
    "    print(f\"\\nClassification on tasks: {selected_tasks}\\n\")\n",
    "    for name, clf in classifiers.items():\n",
    "        scores = cross_val_score(clf, X, y_encoded, cv=5)\n",
    "        print(f\"{name}: Accuracy = {np.mean(scores)*100:.2f}%\")\n",
    "\n",
    "        if len(set(y_encoded)) == 2:  # Binary classification\n",
    "            probs = cross_val_predict(clf, X, y_encoded, cv=5, method='predict_proba')[:, 1]\n",
    "            auc = roc_auc_score(y_encoded, probs)\n",
    "            print(f\"         AUC = {auc:.2f}\")\n",
    "\n",
    "set_plotting_style()\n",
    "\n",
    "def classify_tasks(best_networks, selected_tasks=None, classifier_name=\"Random Forest\", channels_labels=None, all_nodes=[i for i in range(62)], top_n=20):\n",
    "\n",
    "    best_networks = [net for net in best_networks if net['task'] in selected_tasks]\n",
    "\n",
    "    # Build feature matrix\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for net in best_networks:\n",
    "        node_set = set(net['net_nodes'])\n",
    "        feature_vector = [1 if node in node_set else 0 for node in all_nodes]\n",
    "        X.append(feature_vector)\n",
    "        y.append(net['task'])\n",
    "\n",
    "    X = pd.DataFrame(X, columns=all_nodes)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # Classifier options\n",
    "    classifiers = {\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"SVM\": SVC(kernel='linear', probability=True, random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "    }\n",
    "\n",
    "    clf = classifiers.get(classifier_name, RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "\n",
    "    # Cross-validation\n",
    "    scores = cross_val_score(clf, X, y_encoded, cv=5)\n",
    "    print(f\"Using {classifier_name}\")\n",
    "    print(\"Tasks:\", sorted(set(y)))\n",
    "    print(\"Mean Classification Accuracy: {:.2f}%\".format(np.mean(scores) * 100))\n",
    "\n",
    "    # Train on full data\n",
    "    clf.fit(X, y_encoded)\n",
    "\n",
    "    # Feature importance or coefficients\n",
    "    if classifier_name in [\"Random Forest\", \"Gradient Boosting\"]:\n",
    "        importances = clf.feature_importances_\n",
    "    elif classifier_name in [\"Logistic Regression\", \"SVM\"]:\n",
    "        importances = np.abs(clf.coef_).mean(axis=0)\n",
    "    else:\n",
    "        importances = None  # KNN has no coefficients/feature importances\n",
    "\n",
    "    if importances is not None:\n",
    "        sorted_indices = np.argsort(importances)[::-1]\n",
    "        top_indices = sorted_indices[:top_n]\n",
    "        top_nodes = [all_nodes[i] for i in top_indices]\n",
    "        top_labels = [channels_labels[i] if channels_labels else str(i) for i in top_nodes]\n",
    "        top_importances = [importances[i] for i in top_indices]\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(top_labels, top_importances, color='mediumseagreen')\n",
    "        plt.title(f\"Top EEG Nodes by Importance ({classifier_name})\")\n",
    "        plt.ylabel(\"Importance / Coefficient Magnitude\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return clf, label_encoder, all_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c5c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classifiers_on_tasks(best_networks, selected_tasks=[\"S1\", \"S2\"])\n",
    "\n",
    "clf, enc, nodes = classify_tasks(\n",
    "    best_networks,\n",
    "    selected_tasks=[\"S1\", \"S2\"],\n",
    "    classifier_name=\"Logistic Regression\",\n",
    "    channels_labels=channels_labels,\n",
    "    top_n=15\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7346d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define task groups\n",
    "group_a = ['S1']\n",
    "group_b = ['S4']\n",
    "\n",
    "# Helper to collect node counts\n",
    "def collect_node_counts(best_nets_by_subject, group):\n",
    "    node_counter = Counter()\n",
    "    for subj, stim_dict in best_nets_by_subject.items():\n",
    "        for stim in group:\n",
    "            if stim in stim_dict:\n",
    "                for net in stim_dict[stim]:\n",
    "                    node_counter.update(net['net_nodes'])\n",
    "    return node_counter\n",
    "\n",
    "# Count nodes in each group\n",
    "node_counts_a = collect_node_counts(best_nets_by_subject, group_a)\n",
    "node_counts_b = collect_node_counts(best_nets_by_subject, group_b)\n",
    "\n",
    "# All unique nodes from both groups\n",
    "all_nodes = set(node_counts_a) | set(node_counts_b)\n",
    "\n",
    "# Sort by count\n",
    "sorted_nodes = sorted(all_nodes, key=lambda n: node_counts_a[n] + node_counts_b[n], reverse=True)[:20]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "x = range(len(sorted_nodes))\n",
    "a_vals = [node_counts_a[n] for n in sorted_nodes]\n",
    "b_vals = [node_counts_b[n] for n in sorted_nodes]\n",
    "\n",
    "bar_width = 0.35\n",
    "plt.bar(x, a_vals, width=bar_width, label=group_a[0], color='steelblue')\n",
    "plt.bar([i + bar_width for i in x], b_vals, width=bar_width, label=group_b[0], color='indianred')\n",
    "\n",
    "plt.xticks(\n",
    "    [i + bar_width/2 for i in x],\n",
    "    [channels_labels[n] for n in sorted_nodes],\n",
    "    rotation=45, ha='right'\n",
    ")\n",
    "plt.ylabel(\"Node Frequency\")\n",
    "plt.title(\"EEG Node Frequency in Best Networks\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b97126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary node presence (0/1 for each of the 62 channels)\n",
    "def classify_by_node_presence(networks, node_labels, classifier, bar=False):\n",
    "\n",
    "    all_nodes = sorted({node for net in networks for node in net['net_nodes']})\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for net in networks:\n",
    "        node_set = set(net['net_nodes'])\n",
    "        X.append([1 if node in node_set else 0 for node in all_nodes])\n",
    "        y.append(net['task'])\n",
    "\n",
    "    df_X = pd.DataFrame(X, columns=[node_labels[i] for i in all_nodes])\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "\n",
    "    classifier.fit(df_X, y_enc)\n",
    "    scores = cross_val_score(classifier, df_X, y_enc, cv=5)\n",
    "    print(f\"Node Presence Accuracy: {scores.mean() * 100:.2f}%\")\n",
    "\n",
    "    # Plot feature importances\n",
    "    importances = classifier.feature_importances_\n",
    "    feature_names = df_X.columns\n",
    "\n",
    "    if bar==True:\n",
    "      top_n = 20\n",
    "      indices = np.argsort(importances)[::-1][:top_n]\n",
    "      plt.figure(figsize=(10, 6))\n",
    "      plt.bar([feature_names[i] for i in indices], [importances[i] for i in indices], color='teal')\n",
    "      plt.xticks(rotation=45, ha='right')\n",
    "      plt.title(f\"Top {top_n} Feature Importances\")\n",
    "      plt.ylabel(\"Importance\")\n",
    "      plt.tight_layout()\n",
    "      plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 1.5))\n",
    "    sns.heatmap([importances], cmap='magma', xticklabels=feature_names)\n",
    "    plt.title(\"Feature Importances (Heatmap)\")\n",
    "    plt.yticks([])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Cognitive function counts (frequency of function keywords in the net nodes)\n",
    "def classify_by_function_keywords(networks, node_functions, classifier):\n",
    "\n",
    "    all_functions = sorted({func for funcs in node_functions.values() for func in funcs})\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for net in networks:\n",
    "        func_counter = Counter()\n",
    "        for node in net['net_nodes']:\n",
    "            functions = node_functions.get(node, [])\n",
    "            func_counter.update(functions)\n",
    "        X.append([func_counter.get(f, 0) for f in all_functions])\n",
    "        y.append(net['task'])\n",
    "\n",
    "    df_X = pd.DataFrame(X, columns=all_functions)\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "\n",
    "    classifier.fit(df_X, y_enc)\n",
    "    scores = cross_val_score(classifier, df_X, y_enc, cv=5)\n",
    "    print(f\"Function Keyword Accuracy: {scores.mean() * 100:.2f}%\")\n",
    "\n",
    "    importances = classifier.feature_importances_\n",
    "    feature_names = df_X.columns\n",
    "\n",
    "    plt.figure(figsize=(12, 1.5))\n",
    "    sns.heatmap([importances], cmap='magma', xticklabels=feature_names)\n",
    "    plt.title(\"Feature Importances (Heatmap)\")\n",
    "    plt.yticks([])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f0cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subject(id=1, data_folder=output_folder):\n",
    "    \"\"\"\n",
    "    Load all networks for a single subject, ensuring data exists for all tasks S1–S7.\n",
    "\n",
    "    Parameters:\n",
    "    - id (int): Subject ID to load.\n",
    "    - data_folder (str): Path to folder containing the .xlsx network files.\n",
    "\n",
    "    Returns:\n",
    "    - all_networks (list of dicts): Each dict has keys: subject, task, net_nodes, pec, tags.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError if any of the tasks (S1–S7) are missing.\n",
    "    \"\"\"\n",
    "    expected_tasks = {f\"S{i}\" for i in range(1, 7)}\n",
    "    all_networks = []\n",
    "    found_tasks = set()\n",
    "\n",
    "    pattern = re.compile(r'nets_(3down|23|12)_(S\\d+)_(\\d+)\\.xlsx$')\n",
    "    files = glob.glob(os.path.join(data_folder, f\"nets_*_S*_{id}.xlsx\"))\n",
    "\n",
    "    for file in files:\n",
    "        match = pattern.search(file)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        sigma, task, subject_id = match.groups()\n",
    "        found_tasks.add(task)\n",
    "\n",
    "        subject_id = f\"subj{subject_id}\"\n",
    "        df = parse_subject_file(file)\n",
    "\n",
    "        # Temp dict to collect unique networks\n",
    "        net_dict = {}\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            key = (task, subject_id, row['Net Nodes'])\n",
    "            if key not in net_dict:\n",
    "                net_dict[key] = {\n",
    "                    'task': task,\n",
    "                    'subject': subject_id,\n",
    "                    'net_nodes': row['Net Nodes'],\n",
    "                    'pec': row['Last PEC Value'],\n",
    "                    'tags': set(row['Processing Tags']),\n",
    "                }\n",
    "            else:\n",
    "                net_dict[key]['tags'].update(row['Processing Tags'])\n",
    "\n",
    "        # Add unique entries to the result\n",
    "        for net in net_dict.values():\n",
    "            net['tags'] = sorted(net['tags'])  # optional\n",
    "            all_networks.append(net)\n",
    "\n",
    "    # Check if all required tasks are present\n",
    "    missing_tasks = expected_tasks - found_tasks\n",
    "    if missing_tasks:\n",
    "        raise ValueError(f\"Subject {id} is missing data for task(s): {', '.join(sorted(missing_tasks))}\")\n",
    "\n",
    "    return all_networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f059364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subject network data\n",
    "subject_data = None\n",
    "\n",
    "try:\n",
    "    subject_data = load_subject(id=4)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "\n",
    "classification_data = subject_data\n",
    "\n",
    "all_functions = sorted({func for funcs in node_functions.values() for func in funcs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a7a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "classify_by_node_presence(classification_data, channels_labels, classifier)\n",
    "classify_by_function_keywords(classification_data, node_functions, classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df09cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_weights = {\n",
    "    # General / always-on (low base score)\n",
    "    'attention': 0.2,\n",
    "    'executive function': 0.2,\n",
    "    'working memory': 0.2,\n",
    "\n",
    "    'emotional control': 0.2,\n",
    "    'spatial awareness': 0.4,\n",
    "    'sensorimotor integration': 0.45,\n",
    "    'visual attention': 0.45,\n",
    "\n",
    "    # Task-specific (medium to high)\n",
    "    'primary visual cortex (left visual field)': 0.5,\n",
    "    'primary visual cortex (right visual field)': 0.5,\n",
    "    'visual integration': 0.55,\n",
    "    'auditory-motor integration': 0.65,\n",
    "    'visual spatial processing': 0.7,\n",
    "    'object recognition': 0.75,\n",
    "    'high-level visual processing': 0.8,\n",
    "    'auditory processing': 0.9,\n",
    "    'primary auditory processing': 0.9,\n",
    "    'speech perception': 0.9,\n",
    "    'speech and language integration': 0.9,\n",
    "    'language': 0.95,\n",
    "    'language processing': 0.95,\n",
    "\n",
    "\n",
    "    # Other (moderate)\n",
    "    'decision making': 0.5,\n",
    "    'motor planning': 0.75,\n",
    "    'motor cortex - movement of left limbs': 0.5,\n",
    "    'motor cortex - movement of right limbs': 0.5,\n",
    "    'conflict monitoring': 0.6,\n",
    "    'spatial processing': 0.65,\n",
    "    'emotional regulation': 0.3,\n",
    "    'tactile processing': 0.3,\n",
    "    'sound localization': 0.8,\n",
    "    'auditory association': 0.8,\n",
    "    'visual processing': 0.6,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_function_vectors(networks, node_functions, function_weights, plot_type='heatmap'):\n",
    "    # Get all cognitive functions mapped by the 64-channel EEG\n",
    "    all_functions = sorted({func for funcs in node_functions.values() for func in funcs})\n",
    "\n",
    "    # Normalize PECs across all networks\n",
    "    all_pecs = [net['pec'] for net in networks]\n",
    "    max_pec = max(all_pecs)\n",
    "    min_pec = min(all_pecs)\n",
    "\n",
    "    def normalize_pec(pec):\n",
    "        return 1 - (pec - min_pec) / (max_pec - min_pec + 1e-6)\n",
    "\n",
    "    data = []\n",
    "    ids = []\n",
    "\n",
    "    for net in networks:\n",
    "        weighted_vector = defaultdict(float)\n",
    "        pec_weight = normalize_pec(net['pec'])\n",
    "\n",
    "        for node in net['net_nodes']:\n",
    "            funcs = node_functions.get(node, [])\n",
    "            for f in funcs:\n",
    "                base_weight = function_weights.get(f, 0.0)\n",
    "                weighted_vector[f] += pec_weight * base_weight\n",
    "\n",
    "        vec = [weighted_vector.get(f, 0.0) for f in all_functions]\n",
    "        data.append(vec)\n",
    "        ids.append(f\"{net['subject']}_{net['task']}\")\n",
    "\n",
    "    df = pd.DataFrame(data, columns=all_functions, index=ids)\n",
    "\n",
    "    if plot_type == 'bar':\n",
    "        avg_weights = df.mean().sort_values(ascending=False)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x=avg_weights.values, y=avg_weights.index, palette=\"viridis\")\n",
    "        plt.title(\"Average PEC-weighted Function Contributions\")\n",
    "        plt.xlabel(\"Weighted Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    elif plot_type == 'heatmap':\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        sns.heatmap(df.T, cmap=\"mako\", cbar_kws={'label': 'PEC-weighted score'})\n",
    "        plt.title(\"Function Contributions Across Networks\")\n",
    "        plt.xlabel(\"Networks\")\n",
    "        plt.ylabel(\"Functions\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d7f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors = generate_function_vectors(classification_data, node_functions, function_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0caf288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def plot_dimensionality_reduction(df_vectors, method='pca'):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df_vectors.values)\n",
    "    labels = [idx.split('_')[1] for idx in df_vectors.index]\n",
    "\n",
    "    if method == 'pca':\n",
    "        reducer = PCA(n_components=2)\n",
    "        X_red = reducer.fit_transform(X_scaled)\n",
    "        title = 'PCA of Function Vectors'\n",
    "    elif method == 'tsne':\n",
    "        reducer = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "        X_red = reducer.fit_transform(X_scaled)\n",
    "        title = 't-SNE of Function Vectors'\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'pca' or 'tsne'\")\n",
    "\n",
    "    df_plot = pd.DataFrame(X_red, columns=['Dim1', 'Dim2'])\n",
    "    df_plot['Task'] = labels\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(data=df_plot, x='Dim1', y='Dim2', hue='Task', palette='Set2', s=80)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_dimensionality_reduction(df_vectors, method='pca')\n",
    "plot_dimensionality_reduction(df_vectors, method='tsne')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56785112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import label_binarize, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def classify_tasks_v2(df_vectors, classifier=None, plot=True):\n",
    "    # Prepare features and labels\n",
    "    X = df_vectors.values\n",
    "    y_raw = [idx.split('_')[1] for idx in df_vectors.index]\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y_raw)\n",
    "    class_labels = le.classes_\n",
    "\n",
    "    # Initialize classifier\n",
    "    if classifier is None:\n",
    "        classifier = SVC(kernel='linear', probability=True, random_state=42, class_weight='balanced')\n",
    "\n",
    "    # K-Fold Cross Validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "    auc_scores = []\n",
    "    confusion_matrix_all = np.zeros((len(np.unique(y)), len(np.unique(y))))\n",
    "    skipped_auc_folds = 0\n",
    "\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        y_pred_prob = classifier.predict_proba(X_test)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        all_y_true.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)\n",
    "\n",
    "        if set(np.unique(y_test)) == set(np.unique(y)):\n",
    "            y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
    "            auc_score = roc_auc_score(y_test_bin, y_pred_prob, average='weighted', multi_class='ovr')\n",
    "            auc_scores.append(auc_score)\n",
    "        else:\n",
    "            skipped_auc_folds += 1\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=np.unique(y))\n",
    "        confusion_matrix_all += cm\n",
    "\n",
    "    print(f\"\\nAverage F1 Score (weighted): {np.mean(f1_scores):.2f}\")\n",
    "    if auc_scores:\n",
    "        print(f\"Average AUC (weighted): {np.mean(auc_scores):.2f}\")\n",
    "    else:\n",
    "        print(f\"AUC not calculated for {skipped_auc_folds} fold(s) due to missing classes.\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_all.astype(int),\n",
    "                                  display_labels=le.inverse_transform(np.unique(y)))\n",
    "    disp.plot(cmap='Blues', values_format='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Class-wise accuracy and sample counts\n",
    "    total_per_class = np.bincount(y)\n",
    "    correct_per_class = np.diag(confusion_matrix_all)\n",
    "    accuracy_per_class = correct_per_class / total_per_class\n",
    "\n",
    "    print(\"\\nClass-wise accuracy and sample count:\")\n",
    "    for label, acc, count in zip(class_labels, accuracy_per_class, total_per_class):\n",
    "        print(f\"  - {label}: {acc:.2f} accuracy over {int(count)} samples\")\n",
    "\n",
    "    # Classification report (precision, recall, f1 for each class)\n",
    "    print(\"\\n📄 Classification report:\")\n",
    "    print(classification_report(all_y_true, all_y_pred, target_names=class_labels))\n",
    "\n",
    "    # Feature importance heatmap\n",
    "    if plot and hasattr(classifier, 'coef_'):\n",
    "        importances = np.mean(np.abs(classifier.coef_), axis=0)\n",
    "        if importances.shape[0] == df_vectors.shape[1]:\n",
    "            top_idx = np.argsort(importances)[::-1][:30]\n",
    "            top_features = np.array(df_vectors.columns)[top_idx]\n",
    "            top_importances = importances[top_idx]\n",
    "\n",
    "            heat_df = pd.DataFrame({'Feature': top_features, 'Importance': top_importances})\n",
    "            heat_df = heat_df.set_index('Feature').T\n",
    "\n",
    "            plt.figure(figsize=(14, 2))\n",
    "            sns.heatmap(heat_df, cmap='YlGnBu', annot=False, cbar=True)\n",
    "            plt.title(\"Top 30 Feature Importances\")\n",
    "            plt.yticks(rotation=0)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Skipped feature importance plot: {importances.shape[0]} model coefficients vs {df_vectors.shape[1]} feature columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca458e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_tasks_v2(df_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39654e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for subject_id in range(1, 25):\n",
    "    print(f\"\\nSubject {subject_id}\")\n",
    "    try:\n",
    "        subject_data = load_subject(id=subject_id)\n",
    "        df_vectors = generate_function_vectors(subject_data, node_functions, function_weights, plot_type=None)\n",
    "\n",
    "        metrics = {\n",
    "            'subject': subject_id,\n",
    "            'f1_scores': [],\n",
    "            'auc_scores': [],\n",
    "            'class_accuracies': {},\n",
    "            'class_counts': {},\n",
    "            'feature_importances': {}\n",
    "        }\n",
    "\n",
    "        # Local capture of classification results\n",
    "        class LocalClassifierLogger:\n",
    "            def __init__(self):\n",
    "                self.y_true = []\n",
    "                self.y_pred = []\n",
    "                self.cm_all = None\n",
    "                self.f1_scores = []\n",
    "                self.auc_scores = []\n",
    "                self.class_labels = []\n",
    "                self.class_counts = None\n",
    "                self.accuracy_per_class = None\n",
    "                self.feature_importances = None\n",
    "\n",
    "        logger = LocalClassifierLogger()\n",
    "\n",
    "        def classify_and_capture(df_vectors, logger, classifier=None, plot=False):\n",
    "\n",
    "          X = df_vectors.values\n",
    "          y_raw = [idx.split('_')[1] for idx in df_vectors.index]\n",
    "\n",
    "          # Remove under-represented classes\n",
    "          class_counts_raw = pd.Series(y_raw).value_counts()\n",
    "          min_samples = 5\n",
    "          valid_classes = class_counts_raw[class_counts_raw >= min_samples].index.tolist()\n",
    "\n",
    "          # Filter raw labels and data\n",
    "          mask = [label in valid_classes for label in y_raw]\n",
    "          X = X[mask]\n",
    "          y_raw = np.array(y_raw)[mask]\n",
    "          df_vectors = df_vectors.iloc[mask]\n",
    "\n",
    "          # Label encode\n",
    "          le = LabelEncoder()\n",
    "          y = le.fit_transform(y_raw)\n",
    "          logger.class_labels = le.classes_\n",
    "\n",
    "\n",
    "          if classifier is None:\n",
    "              classifier = SVC(kernel='linear', probability=True, random_state=42, class_weight='balanced')\n",
    "\n",
    "          skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "          logger.cm_all = np.zeros((len(np.unique(y)), len(np.unique(y))))\n",
    "          skipped_auc_folds = 0\n",
    "\n",
    "          for train_idx, test_idx in skf.split(X, y):\n",
    "              X_train, X_test = X[train_idx], X[test_idx]\n",
    "              y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "              # Fit model\n",
    "              classifier.fit(X_train, y_train)\n",
    "\n",
    "              # Predictions\n",
    "              y_pred = classifier.predict(X_test)\n",
    "              logger.y_true.extend(y_test)\n",
    "              logger.y_pred.extend(y_pred)\n",
    "\n",
    "              # F1 Score\n",
    "              f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "              logger.f1_scores.append(f1)\n",
    "\n",
    "              # AUC Score — only if proba matches class count\n",
    "              if hasattr(classifier, \"predict_proba\"):\n",
    "                  y_pred_prob = classifier.predict_proba(X_test)\n",
    "\n",
    "                  # Proceed only if class count matches and test includes all classes\n",
    "                  if (y_pred_prob.shape[1] == len(le.classes_)) and (set(np.unique(y_test)) == set(np.unique(y))):\n",
    "                      y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
    "                      auc = roc_auc_score(y_test_bin, y_pred_prob, average='weighted', multi_class='ovr')\n",
    "                      logger.auc_scores.append(auc)\n",
    "                  else:\n",
    "                      skipped_auc_folds += 1\n",
    "\n",
    "              # Update confusion matrix\n",
    "              cm = confusion_matrix(y_test, y_pred, labels=np.unique(y))\n",
    "              logger.cm_all += cm\n",
    "\n",
    "          total_per_class = np.bincount(y)\n",
    "          correct_per_class = np.diag(logger.cm_all)\n",
    "          logger.accuracy_per_class = correct_per_class / total_per_class\n",
    "          logger.class_counts = total_per_class\n",
    "\n",
    "          # Feature importances (if linear classifier)\n",
    "          if hasattr(classifier, 'coef_'):\n",
    "              importances = np.mean(np.abs(classifier.coef_), axis=0)\n",
    "              if importances.shape[0] == df_vectors.shape[1]:\n",
    "                  feature_names = df_vectors.columns\n",
    "                  top_idx = np.argsort(importances)[::-1]\n",
    "                  logger.feature_importances = dict(zip(feature_names[top_idx], importances[top_idx]))\n",
    "\n",
    "\n",
    "        # Run classification\n",
    "        classify_and_capture(df_vectors, logger)\n",
    "\n",
    "        # Store results\n",
    "        metrics['f1_scores'] = logger.f1_scores\n",
    "        metrics['auc_scores'] = logger.auc_scores\n",
    "        metrics['f1'] = float(np.nan_to_num(np.mean(logger.f1_scores), nan=0.0))\n",
    "        metrics['auc'] = float(np.nan_to_num(np.mean(logger.auc_scores), nan=0.0))\n",
    "        metrics['class_accuracies'] = dict(zip(logger.class_labels, logger.accuracy_per_class))\n",
    "        metrics['class_counts'] = dict(zip(logger.class_labels, logger.class_counts))\n",
    "        if logger.feature_importances:\n",
    "            metrics['feature_importances'] = logger.feature_importances\n",
    "\n",
    "        results.append(metrics)\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping Subject {subject_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Example: convert to DataFrame\n",
    "df_summary = pd.DataFrame(results)\n",
    "\n",
    "# Optional: save to CSV\n",
    "df_summary.to_csv(project_root/'data/results/eeg/subject_classification_summary.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aab657",
   "metadata": {},
   "source": [
    "More careful classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b01498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    f1_score, roc_auc_score, average_precision_score,\n",
    "    precision_score, recall_score, confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "def compute_classification_metrics(X, y_raw, classifier, le, n_classes):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y = le.transform(y_raw)\n",
    "\n",
    "    metrics = {\n",
    "        'f1_macro': [],\n",
    "        'f1_weighted': [],\n",
    "        'roc_auc': [],\n",
    "        'pr_auc': [],\n",
    "        'precision_weighted': [],\n",
    "        'recall_weighted': [],\n",
    "        'confusion_matrices': []\n",
    "    }\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        # AUC and PR-AUC\n",
    "        if hasattr(classifier, \"predict_proba\"):\n",
    "            y_prob = classifier.predict_proba(X_test)\n",
    "            if y_prob.shape[1] == n_classes:\n",
    "                y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "                metrics['roc_auc'].append(\n",
    "                    roc_auc_score(y_test_bin, y_prob, average='weighted', multi_class='ovr')\n",
    "                )\n",
    "                metrics['pr_auc'].append(\n",
    "                    average_precision_score(y_test_bin, y_prob, average='weighted')\n",
    "                )\n",
    "\n",
    "        # Core classification metrics\n",
    "        metrics['f1_macro'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "        metrics['f1_weighted'].append(f1_score(y_test, y_pred, average='weighted'))\n",
    "        metrics['precision_weighted'].append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        metrics['recall_weighted'].append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        metrics['confusion_matrices'].append(confusion_matrix(y_test, y_pred, labels=np.arange(n_classes)))\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Subject loop (simplified)\n",
    "for subject_id in range(1, 25):\n",
    "    try:\n",
    "        subject_data = load_subject(id=subject_id)\n",
    "        df_vectors = generate_function_vectors(subject_data, node_functions, function_weights, plot_type=None)\n",
    "\n",
    "        y_raw = [idx.split('_')[1] for idx in df_vectors.index]\n",
    "        class_counts_raw = pd.Series(y_raw).value_counts()\n",
    "        min_samples = 5\n",
    "        valid_classes = class_counts_raw[class_counts_raw >= min_samples].index.tolist()\n",
    "        mask = [label in valid_classes for label in y_raw]\n",
    "        df_vectors = df_vectors.iloc[mask]\n",
    "        y_raw = np.array(y_raw)[mask]\n",
    "        X = df_vectors.values\n",
    "\n",
    "        if len(np.unique(y_raw)) < 2:\n",
    "            print(f\"Skipping Subject {subject_id}: Not enough valid classes\")\n",
    "            continue\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        le.fit(y_raw)\n",
    "        n_classes = len(le.classes_)\n",
    "        classifier = SVC(kernel='linear', probability=True, random_state=42, class_weight='balanced')\n",
    "\n",
    "        detailed_metrics = compute_classification_metrics(X, y_raw, classifier, le, n_classes)\n",
    "\n",
    "        result = {\n",
    "            'subject': subject_id,\n",
    "            'f1_macro': float(np.nanmean(detailed_metrics['f1_macro'])),\n",
    "            'f1_weighted': float(np.nanmean(detailed_metrics['f1_weighted'])),\n",
    "            'precision_weighted': float(np.nanmean(detailed_metrics['precision_weighted'])),\n",
    "            'recall_weighted': float(np.nanmean(detailed_metrics['recall_weighted'])),\n",
    "            'roc_auc': float(np.nanmean(detailed_metrics['roc_auc'])) if detailed_metrics['roc_auc'] else np.nan,\n",
    "            'pr_auc': float(np.nanmean(detailed_metrics['pr_auc'])) if detailed_metrics['pr_auc'] else np.nan,\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping Subject {subject_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Final results DataFrame\n",
    "df_summary = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe633d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = pd.read_csv(project_root/'data/results/eeg/subject_classification_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944fc6cd",
   "metadata": {},
   "source": [
    "Check F1 and AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "set_plotting_style()\n",
    "\n",
    "df_long = df_summary[['subject', 'f1', 'auc']].melt(id_vars='subject', var_name='metric', value_name='score')\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n",
    "\n",
    "# Use gray to reduce unnecessary emphasis\n",
    "bar_color = 'gray'\n",
    "\n",
    "# F1 subplot\n",
    "sns.barplot(data=df_summary, x='subject', y='f1', color=bar_color, ax=axes[0])\n",
    "axes[0].set_title('Task Prediction Scores', pad=10)\n",
    "axes[0].set_ylabel('F1 Score')\n",
    "axes[0].set_ylim(0, 1.05)\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.4)\n",
    "axes[0].set_xlabel('')  # Remove x-axis label\n",
    "\n",
    "# AUC subplot\n",
    "sns.barplot(data=df_summary, x='subject', y='auc', color=bar_color, ax=axes[1])\n",
    "axes[1].set_ylabel('ROC-AUC')\n",
    "axes[1].set_ylim(0, 1.05)\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.4)\n",
    "axes[1].set_xlabel('')  # Remove default x-axis label\n",
    "\n",
    "# Add single, centered x-axis label below both subplots\n",
    "fig.text(0.5, 0.01, 'Subject ID', ha='center', va='center')\n",
    "\n",
    "# Rotate ticks and finalize layout\n",
    "plt.setp(axes[1].xaxis.get_majorticklabels(), rotation=90)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 1])  # Leave space at bottom for xlabel\n",
    "\n",
    "# Save and show\n",
    "plt.savefig(figures_folder / \"F1_AUC_CleanSubplots.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d3ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "set_plotting_style()\n",
    "\n",
    "df_long = df_summary[['subject', 'f1', 'auc']].melt(id_vars='subject', var_name='metric', value_name='score')\n",
    "\n",
    "df_long['metric'] = df_long['metric'].map({'f1': 'F1', 'auc': 'ROC-AUC'})\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df_long, x='subject', y='score', hue='metric', palette='gray')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Subject ID', labelpad=15)\n",
    "plt.ylabel('')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Task Prediction Scores', pad=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "plt.savefig(figures_folder / \"F1_AUC_GroupedBar.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0782e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "set_plotting_style()\n",
    "\n",
    "# Prepare data in long format\n",
    "df_long = df_summary[['subject', 'f1', 'auc']].melt(id_vars='subject', var_name='metric', value_name='score')\n",
    "\n",
    "plt.figure(figsize=(4,5))\n",
    "\n",
    "# Boxplot with datapoints overlay\n",
    "sns.boxplot(data=df_long, x='metric', y='score', color='lightgray', fliersize=0, width=0.5)\n",
    "sns.stripplot(data=df_long, x='metric', y='score', color='black', size=6, jitter=True, alpha=0.7)\n",
    "\n",
    "plt.title('Task Prediction Scores', pad=10)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.ylabel('')\n",
    "plt.xlabel('')\n",
    "plt.xticks([0, 1], ['F1', 'ROC-AUC'], fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(figures_folder / \"AUC_F1_Boxplot.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6de0a28",
   "metadata": {},
   "source": [
    "Check class accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0020ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "from scipy.stats import ttest_rel\n",
    "from itertools import combinations\n",
    "\n",
    "# 1. Prepare Accuracy Data\n",
    "acc_records = []\n",
    "\n",
    "for _, row in df_summary.iterrows():\n",
    "    subject = row['subject']\n",
    "    acc_dict = eval(row['class_accuracies'], {\"np\": np})\n",
    "    for task, acc in acc_dict.items():\n",
    "        acc_records.append({'subject': subject, 'task': task, 'accuracy': acc})\n",
    "\n",
    "acc_df = pd.DataFrame(acc_records)\n",
    "acc_df['accuracy'] = acc_df['accuracy'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "task_order = ['S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7']\n",
    "acc_df['task'] = pd.Categorical(acc_df['task'], categories=task_order, ordered=True)\n",
    "\n",
    "task_labels = {\n",
    "    'S1': 'Original',\n",
    "    'S2': 'Scrambled',\n",
    "    'S3': 'Randomized',\n",
    "    'S4': 'Original',\n",
    "    'S5': 'Scrambled',\n",
    "    'S6': 'Randomized',\n",
    "    'S7': 'Rest'\n",
    "}\n",
    "\n",
    "# 2. Define Color Palette\n",
    "custom_palette = {\n",
    "    'S1': '#a6dba0',  # light teal\n",
    "    'S2': '#5aae61',  # medium teal\n",
    "    'S3': '#1b7837',  # dark teal\n",
    "    'S4': '#80cdc1',  # light blue\n",
    "    'S5': '#4393c3',  # medium blue\n",
    "    'S6': '#2166ac',  # dark blue\n",
    "    'S7': '#bdbdbd'   # gray\n",
    "}\n",
    "\n",
    "# 3. Compute Statistical Tests\n",
    "task_pairs = list(combinations(task_order, 2))\n",
    "p_values = []\n",
    "\n",
    "from scipy.stats import ttest_rel, wilcoxon, mannwhitneyu, shapiro\n",
    "\n",
    "p_values = []\n",
    "test_types = []\n",
    "\n",
    "for task1, task2 in task_pairs:\n",
    "    d1 = acc_df[acc_df['task'] == task1].sort_values('subject')\n",
    "    d2 = acc_df[acc_df['task'] == task2].sort_values('subject')\n",
    "\n",
    "    common_subjects = set(d1['subject']) & set(d2['subject'])\n",
    "    d1_common = d1[d1['subject'].isin(common_subjects)]\n",
    "    d2_common = d2[d2['subject'].isin(common_subjects)]\n",
    "\n",
    "    d1_vals = d1_common['accuracy'].values\n",
    "    d2_vals = d2_common['accuracy'].values\n",
    "\n",
    "    # CASE 1: Paired design (same subjects in both)\n",
    "    if len(d1_vals) > 0 and len(d1_vals) == len(d2_vals):\n",
    "        diff = d1_vals - d2_vals\n",
    "\n",
    "        # Check for normality of differences\n",
    "        if len(diff) >= 3:  # Shapiro needs at least 3 samples\n",
    "            _, p_norm = shapiro(diff)\n",
    "        else:\n",
    "            p_norm = 1.0  # Assume normal if too few samples\n",
    "\n",
    "        if p_norm > 0.05:\n",
    "            stat, p = ttest_rel(d1_vals, d2_vals)\n",
    "            test = 'paired t-test'\n",
    "        else:\n",
    "            try:\n",
    "                stat, p = wilcoxon(d1_vals, d2_vals)\n",
    "                test = 'wilcoxon'\n",
    "            except ValueError:\n",
    "                p = 1.0\n",
    "                test = 'wilcoxon (fail)'\n",
    "        \n",
    "        p_values.append(((task1, task2), p))\n",
    "        test_types.append(((task1, task2), test))\n",
    "\n",
    "    # CASE 2: Unpaired design\n",
    "    else:\n",
    "        d1_vals = d1['accuracy'].values\n",
    "        d2_vals = d2['accuracy'].values\n",
    "        try:\n",
    "            stat, p = mannwhitneyu(d1_vals, d2_vals, alternative='two-sided')\n",
    "            test = 'mannwhitney'\n",
    "        except ValueError:\n",
    "            p = 1.0\n",
    "            test = 'mannwhitney (fail)'\n",
    "\n",
    "        p_values.append(((task1, task2), p))\n",
    "        test_types.append(((task1, task2), test))\n",
    "\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001: return '***'\n",
    "    elif p < 0.01: return '**'\n",
    "    elif p < 0.05: return '*'\n",
    "    else: return 'n.s.'\n",
    "\n",
    "def add_sig_bar(ax, x1, x2, y, h, p):\n",
    "    bar_x = [x1, x1, x2, x2]\n",
    "    bar_y = [y, y+h, y+h, y]\n",
    "    ax.plot(bar_x, bar_y, c='k', lw=1)\n",
    "    ax.text((x1 + x2)/2, y + h + 0.01, pval_to_stars(p), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# 4. Plotting\n",
    "plt.figure(figsize=(14, 6))\n",
    "ax = sns.boxplot(data=acc_df, x='task', y='accuracy', palette=custom_palette)\n",
    "sns.stripplot(data=acc_df, x='task', y='accuracy', color='black', alpha=0.3, jitter=True)\n",
    "\n",
    "# Custom X-axis labels\n",
    "ax.set_xticklabels([task_labels[t] for t in task_order])\n",
    "\n",
    "# Group dividers\n",
    "plt.axvline(x=2.5, color='gray', linestyle='--', linewidth=1)\n",
    "plt.axvline(x=5.5, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "# Group titles\n",
    "plt.text(1, 1.03, 'Audiobook', ha='center', fontsize=14, color='#1b7837', weight='bold')\n",
    "plt.text(4, 1.03, 'Video', ha='center', fontsize=14, color='#2166ac', weight='bold')\n",
    "plt.text(6, 1.03, 'Rest', ha='center', fontsize=14, color='#555555', weight='bold')\n",
    "\n",
    "# (Optional) Subject-level trends\n",
    "# for subject in acc_df['subject'].unique():\n",
    "#     subject_data = acc_df[acc_df['subject'] == subject].sort_values('task')\n",
    "#     plt.plot(subject_data['task'].cat.codes, subject_data['accuracy'], color='gray', alpha=0.2, linewidth=0.8)\n",
    "\n",
    "# Add significance bars\n",
    "start_y = 1.01\n",
    "bar_height = 0.02\n",
    "visible_pvals = [((t1, t2), p) for ((t1, t2), p) in p_values if p < 0.05]\n",
    "\n",
    "for idx, ((t1, t2), p) in enumerate(visible_pvals):\n",
    "    x1 = task_order.index(t1)\n",
    "    x2 = task_order.index(t2)\n",
    "    y = start_y + idx * (bar_height + 0.005)\n",
    "    # add_sig_bar(ax, x1, x2, y, bar_height, p)\n",
    "\n",
    "# Final layout\n",
    "plt.title('Class-wise Accuracy Across Subjects', pad=20)\n",
    "plt.ylim(0, 1.05 + len(visible_pvals)*0.03)\n",
    "plt.ylabel('Accuracy', labelpad=15)\n",
    "plt.xlabel('')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "plt.savefig(figures_folder / \"Class_Accuracy_Final_with_Stats.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c782f",
   "metadata": {},
   "source": [
    "Check feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad75735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict_simple(dict_str):\n",
    "    \"\"\"\n",
    "    Parse a simple dict-like string into a dictionary.\n",
    "    Assumes format like: \"key1: val1, key2: val2, key3: val3\"\n",
    "    Keys and values can be stripped of whitespace.\n",
    "    Values will be kept as strings.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    # Remove possible surrounding braces and whitespace\n",
    "    dict_str = dict_str.strip().strip('{}').strip()\n",
    "    if not dict_str:\n",
    "        return result\n",
    "    \n",
    "    items = dict_str.split(',')\n",
    "    for item in items:\n",
    "        if ':' not in item:\n",
    "            continue  # skip if no colon\n",
    "        \n",
    "        key, value = item.strip().split(':', 1)  # split only on first colon\n",
    "        key = key.strip().strip(\"'\\\"\")  # Strip quotes from keys\n",
    "        try:\n",
    "            value = eval(value.strip(), {\"np\": np})\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: failed to parse value '{value.strip()}': {e}\")\n",
    "            continue\n",
    "        result[key] = value\n",
    "    return result\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "all_features = Counter()\n",
    "\n",
    "for fi in df_summary['feature_importances']:\n",
    "    feat_dict = load_dict_simple(fi)\n",
    "    for k, v in list(feat_dict.items())[:10]:\n",
    "        try:\n",
    "            v = float(v)  # force conversion to numeric\n",
    "            all_features[k] += v\n",
    "        except ValueError:\n",
    "            print(f\"Skipping non-numeric feature: {k}={v}\")\n",
    "\n",
    "# Plot top 20 features by cumulative importance\n",
    "top_features = all_features.most_common(20)\n",
    "feat_names, feat_vals = zip(*top_features)\n",
    "\n",
    "set_plotting_style()\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use a clean, elegant color palette\n",
    "sns.barplot(\n",
    "    x=list(feat_vals),\n",
    "    y=list(feat_names),\n",
    "    palette=sns.color_palette(\"viridis\", n_colors=len(feat_vals)),\n",
    "    orient='h'\n",
    ")\n",
    "\n",
    "# Improve labels and aesthetics\n",
    "plt.xlabel('Cumulative Feature Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 20 Features Across Subjects', fontsize=14)\n",
    "\n",
    "# Style tweaks\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.4)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.tight_layout()\n",
    "# Save high-res\n",
    "plt.savefig(figures_folder/f\"Feature_Importance.png\", dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdfc04b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
